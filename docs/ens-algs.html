<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Practical Guide for Machine Learning and R Shiny</title>
  <meta name="description" content="Everything you need (and nothing more) to start a bookdown book.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="A Practical Guide for Machine Learning and R Shiny" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="<a href="https://cmoten.github.io/machine-learning-course-ALU" class="uri">https://cmoten.github.io/machine-learning-course-ALU</a>" />
  
  <meta property="og:description" content="Everything you need (and nothing more) to start a bookdown book." />
  <meta name="github-repo" content="cmoten/machine-learning-course-ALU" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Practical Guide for Machine Learning and R Shiny" />
  
  <meta name="twitter:description" content="Everything you need (and nothing more) to start a bookdown book." />
  

<meta name="author" content="Cardy Moten III">


<meta name="date" content="2018-02-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="non-lin-algs.html">
<link rel="next" href="ml-pe.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning & R Shiny</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ml-overview.html"><a href="ml-overview.html"><i class="fa fa-check"></i><b>1</b> Machine Learning Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="ml-overview.html"><a href="ml-overview.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="ml-overview.html"><a href="ml-overview.html#what-machine-learning-is-not"><i class="fa fa-check"></i><b>1.2</b> What machine learning is not</a><ul>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-require-a-lot-of-data"><i class="fa fa-check"></i>Machine learning models require a lot of data</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-are-not-a-substitute-for-domain-expertise"><i class="fa fa-check"></i>Machine learning models are not a substitute for domain expertise</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-require-constant-maintenance"><i class="fa fa-check"></i>Machine learning models require constant maintenance</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ml-overview.html"><a href="ml-overview.html#what-do-i-need-to-know-to-get-started-with-machine-learning"><i class="fa fa-check"></i><b>1.3</b> What do I need to know to get started with machine learning?</a><ul>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-role-of-data-in-machine-learning"><i class="fa fa-check"></i>The role of data in machine learning</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-difference-between-parametric-and-nonparametric-machine-learning-algorithms"><i class="fa fa-check"></i>The difference between parametric and nonparametric machine learning algorithms</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-difference-between-supervised-unsupervised-and-semi-supervised-learning"><i class="fa fa-check"></i>The difference between supervised, unsupervised and semi-supervised learning</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-bias-variance-tradeoff"><i class="fa fa-check"></i>The bias-variance tradeoff</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#overfitting-and-underfitting-and-what-to-do-about-it"><i class="fa fa-check"></i>Overfitting and underfitting and what to do about it</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lin-algs.html"><a href="lin-algs.html"><i class="fa fa-check"></i><b>2</b> Linear Algorithms</a><ul>
<li class="chapter" data-level="2.1" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent"><i class="fa fa-check"></i><b>2.1</b> Gradient Descent</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#linear-regression-model"><i class="fa fa-check"></i>Linear Regression Model</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#cost-function"><i class="fa fa-check"></i>Cost Function</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#logistic-regression"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent-algorithm"><i class="fa fa-check"></i>Gradient Descent Algorithm</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent-intuition"><i class="fa fa-check"></i>Gradient Descent Intuition</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="lin-algs.html"><a href="lin-algs.html#practical-exercises"><i class="fa fa-check"></i><b>2.2</b> Practical Exercises</a><ul>
<li class="chapter" data-level="2.2.1" data-path="lin-algs.html"><a href="lin-algs.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>2.2.1</b> Simple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lin-algs.html"><a href="lin-algs.html#company-radio-sales"><i class="fa fa-check"></i><b>2.3</b> company radio sales</a></li>
<li class="chapter" data-level="2.4" data-path="lin-algs.html"><a href="lin-algs.html#section"><i class="fa fa-check"></i><b>2.4</b> 1 1 37.8 22.1</a></li>
<li class="chapter" data-level="2.5" data-path="lin-algs.html"><a href="lin-algs.html#section-1"><i class="fa fa-check"></i><b>2.5</b> 2 2 39.3 10.4</a></li>
<li class="chapter" data-level="2.6" data-path="lin-algs.html"><a href="lin-algs.html#section-2"><i class="fa fa-check"></i><b>2.6</b> 3 3 45.9 9.3</a></li>
<li class="chapter" data-level="2.7" data-path="lin-algs.html"><a href="lin-algs.html#section-3"><i class="fa fa-check"></i><b>2.7</b> 4 4 41.3 18.5</a></li>
<li class="chapter" data-level="2.8" data-path="lin-algs.html"><a href="lin-algs.html#section-4"><i class="fa fa-check"></i><b>2.8</b> 5 5 10.8 12.9</a></li>
<li class="chapter" data-level="2.9" data-path="lin-algs.html"><a href="lin-algs.html#section-5"><i class="fa fa-check"></i><b>2.9</b> 6 6 48.9 7.2</a></li>
<li class="chapter" data-level="2.10" data-path="lin-algs.html"><a href="lin-algs.html#iter-1-weight-0.7255664-bias-0.02804636-cost-86.42445"><i class="fa fa-check"></i><b>2.10</b> iter: 1 weight: 0.7255664 bias: 0.02804636 cost: 86.42445</a></li>
<li class="chapter" data-level="2.11" data-path="lin-algs.html"><a href="lin-algs.html#iter-10-weight-0.484637-bias-0.06879067-cost-42.72917"><i class="fa fa-check"></i><b>2.11</b> iter: 10 weight: 0.484637 bias: 0.06879067 cost: 42.72917</a></li>
<li class="chapter" data-level="2.12" data-path="lin-algs.html"><a href="lin-algs.html#iter-20-weight-0.4837035-bias-0.1219333-cost-42.44643"><i class="fa fa-check"></i><b>2.12</b> iter: 20 weight: 0.4837035 bias: 0.1219333 cost: 42.44643</a></li>
<li class="chapter" data-level="2.13" data-path="lin-algs.html"><a href="lin-algs.html#iter-30-weight-0.4820883-bias-0.1747496-cost-42.1673"><i class="fa fa-check"></i><b>2.13</b> iter: 30 weight: 0.4820883 bias: 0.1747496 cost: 42.1673</a><ul>
<li class="chapter" data-level="2.13.1" data-path="lin-algs.html"><a href="lin-algs.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>2.13.1</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="lin-algs.html"><a href="lin-algs.html#company-tv-radio-newspaper-sales"><i class="fa fa-check"></i><b>2.14</b> company TV radio newspaper sales</a></li>
<li class="chapter" data-level="2.15" data-path="lin-algs.html"><a href="lin-algs.html#section-6"><i class="fa fa-check"></i><b>2.15</b> 1 1 230.1 37.8 69.2 22.1</a></li>
<li class="chapter" data-level="2.16" data-path="lin-algs.html"><a href="lin-algs.html#section-7"><i class="fa fa-check"></i><b>2.16</b> 2 2 44.5 39.3 45.1 10.4</a></li>
<li class="chapter" data-level="2.17" data-path="lin-algs.html"><a href="lin-algs.html#section-8"><i class="fa fa-check"></i><b>2.17</b> 3 3 17.2 45.9 69.3 9.3</a></li>
<li class="chapter" data-level="2.18" data-path="lin-algs.html"><a href="lin-algs.html#section-9"><i class="fa fa-check"></i><b>2.18</b> 4 4 151.5 41.3 58.5 18.5</a></li>
<li class="chapter" data-level="2.19" data-path="lin-algs.html"><a href="lin-algs.html#section-10"><i class="fa fa-check"></i><b>2.19</b> 5 5 180.8 10.8 58.4 12.9</a></li>
<li class="chapter" data-level="2.20" data-path="lin-algs.html"><a href="lin-algs.html#section-11"><i class="fa fa-check"></i><b>2.20</b> 6 6 8.7 48.9 75.0 7.2</a></li>
<li class="chapter" data-level="2.21" data-path="lin-algs.html"><a href="lin-algs.html#section-12"><i class="fa fa-check"></i><b>2.21</b> [,1]</a></li>
<li class="chapter" data-level="2.22" data-path="lin-algs.html"><a href="lin-algs.html#intercept-5.5184872"><i class="fa fa-check"></i><b>2.22</b> Intercept 5.5184872</a></li>
<li class="chapter" data-level="2.23" data-path="lin-algs.html"><a href="lin-algs.html#tv-0.5767349"><i class="fa fa-check"></i><b>2.23</b> TV 0.5767349</a></li>
<li class="chapter" data-level="2.24" data-path="lin-algs.html"><a href="lin-algs.html#radio-0.4366550"><i class="fa fa-check"></i><b>2.24</b> radio 0.4366550</a></li>
<li class="chapter" data-level="2.25" data-path="lin-algs.html"><a href="lin-algs.html#newspaper-0.1098191"><i class="fa fa-check"></i><b>2.25</b> newspaper 0.1098191</a><ul>
<li class="chapter" data-level="2.25.1" data-path="lin-algs.html"><a href="lin-algs.html#logistic-regression-1"><i class="fa fa-check"></i><b>2.25.1</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.26" data-path="lin-algs.html"><a href="lin-algs.html#studied-slept-passed"><i class="fa fa-check"></i><b>2.26</b> studied slept passed</a></li>
<li class="chapter" data-level="2.27" data-path="lin-algs.html"><a href="lin-algs.html#section-13"><i class="fa fa-check"></i><b>2.27</b> 1 4.855064 9.63996157 1</a></li>
<li class="chapter" data-level="2.28" data-path="lin-algs.html"><a href="lin-algs.html#section-14"><i class="fa fa-check"></i><b>2.28</b> 2 8.625440 0.05892653 0</a></li>
<li class="chapter" data-level="2.29" data-path="lin-algs.html"><a href="lin-algs.html#section-15"><i class="fa fa-check"></i><b>2.29</b> 3 3.828192 0.72319923 0</a></li>
<li class="chapter" data-level="2.30" data-path="lin-algs.html"><a href="lin-algs.html#section-16"><i class="fa fa-check"></i><b>2.30</b> 4 7.150955 3.89942042 1</a></li>
<li class="chapter" data-level="2.31" data-path="lin-algs.html"><a href="lin-algs.html#section-17"><i class="fa fa-check"></i><b>2.31</b> 5 6.477900 8.19818055 1</a></li>
<li class="chapter" data-level="2.32" data-path="lin-algs.html"><a href="lin-algs.html#section-18"><i class="fa fa-check"></i><b>2.32</b> 6 1.922270 1.33142727 0</a></li>
<li class="chapter" data-level="2.33" data-path="lin-algs.html"><a href="lin-algs.html#iter-1-cost-0.6582674"><i class="fa fa-check"></i><b>2.33</b> iter: 1 cost: 0.6582674</a></li>
<li class="chapter" data-level="2.34" data-path="lin-algs.html"><a href="lin-algs.html#iter-1000-cost-0.4469503"><i class="fa fa-check"></i><b>2.34</b> iter: 1000 cost: 0.4469503</a></li>
<li class="chapter" data-level="2.35" data-path="lin-algs.html"><a href="lin-algs.html#iter-2000-cost-0.3773433"><i class="fa fa-check"></i><b>2.35</b> iter: 2000 cost: 0.3773433</a></li>
<li class="chapter" data-level="2.36" data-path="lin-algs.html"><a href="lin-algs.html#iter-3000-cost-0.3408168"><i class="fa fa-check"></i><b>2.36</b> iter: 3000 cost: 0.3408168</a></li>
<li class="chapter" data-level="2.37" data-path="lin-algs.html"><a href="lin-algs.html#section-19"><i class="fa fa-check"></i><b>2.37</b> [,1]</a></li>
<li class="chapter" data-level="2.38" data-path="lin-algs.html"><a href="lin-algs.html#intercept--3.8281563"><i class="fa fa-check"></i><b>2.38</b> Intercept -3.8281563</a></li>
<li class="chapter" data-level="2.39" data-path="lin-algs.html"><a href="lin-algs.html#studied-0.4802045"><i class="fa fa-check"></i><b>2.39</b> studied 0.4802045</a></li>
<li class="chapter" data-level="2.40" data-path="lin-algs.html"><a href="lin-algs.html#slept-0.3435157"><i class="fa fa-check"></i><b>2.40</b> slept 0.3435157</a></li>
<li class="chapter" data-level="2.41" data-path="lin-algs.html"><a href="lin-algs.html#section-20"><i class="fa fa-check"></i><b>2.41</b> [1] 0.91</a></li>
<li class="chapter" data-level="2.42" data-path="lin-algs.html"><a href="lin-algs.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>2.42</b> Linear Discriminant Analysis</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-intuition"><i class="fa fa-check"></i>LDA Intuition</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-estimates-for-one-predictor"><i class="fa fa-check"></i>LDA Estimates for One Predictor</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-with-miltiple-predictors"><i class="fa fa-check"></i>LDA With Miltiple Predictors</a></li>
</ul></li>
<li class="chapter" data-level="2.43" data-path="lin-algs.html"><a href="lin-algs.html#practical-exercise"><i class="fa fa-check"></i><b>2.43</b> Practical Exercise</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#data-2"><i class="fa fa-check"></i>Data</a></li>
</ul></li>
<li class="chapter" data-level="2.44" data-path="lin-algs.html"><a href="lin-algs.html#x-y"><i class="fa fa-check"></i><b>2.44</b> x y</a></li>
<li class="chapter" data-level="2.45" data-path="lin-algs.html"><a href="lin-algs.html#section-21"><i class="fa fa-check"></i><b>2.45</b> 1 4.667798 0</a></li>
<li class="chapter" data-level="2.46" data-path="lin-algs.html"><a href="lin-algs.html#section-22"><i class="fa fa-check"></i><b>2.46</b> 2 5.509199 0</a></li>
<li class="chapter" data-level="2.47" data-path="lin-algs.html"><a href="lin-algs.html#section-23"><i class="fa fa-check"></i><b>2.47</b> 3 4.702792 0</a></li>
<li class="chapter" data-level="2.48" data-path="lin-algs.html"><a href="lin-algs.html#section-24"><i class="fa fa-check"></i><b>2.48</b> 4 5.956707 0</a></li>
<li class="chapter" data-level="2.49" data-path="lin-algs.html"><a href="lin-algs.html#section-25"><i class="fa fa-check"></i><b>2.49</b> 5 5.738622 0</a></li>
<li class="chapter" data-level="2.50" data-path="lin-algs.html"><a href="lin-algs.html#section-26"><i class="fa fa-check"></i><b>2.50</b> 6 5.027283 0</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-scoring"><i class="fa fa-check"></i>LDA Scoring</a></li>
</ul></li>
<li class="chapter" data-level="2.51" data-path="lin-algs.html"><a href="lin-algs.html#section-27"><i class="fa fa-check"></i><b>2.51</b> [1] 0.5</a></li>
<li class="chapter" data-level="2.52" data-path="lin-algs.html"><a href="lin-algs.html#section-28"><i class="fa fa-check"></i><b>2.52</b> [1] 0.5</a></li>
<li class="chapter" data-level="2.53" data-path="lin-algs.html"><a href="lin-algs.html#section-29"><i class="fa fa-check"></i><b>2.53</b> [1] 4.975416</a></li>
<li class="chapter" data-level="2.54" data-path="lin-algs.html"><a href="lin-algs.html#section-30"><i class="fa fa-check"></i><b>2.54</b> [1] 20.08706</a></li>
<li class="chapter" data-level="2.55" data-path="lin-algs.html"><a href="lin-algs.html#section-31"><i class="fa fa-check"></i><b>2.55</b> [1] 10.15823</a></li>
<li class="chapter" data-level="2.56" data-path="lin-algs.html"><a href="lin-algs.html#section-32"><i class="fa fa-check"></i><b>2.56</b> [1] 21.49317</a></li>
<li class="chapter" data-level="2.57" data-path="lin-algs.html"><a href="lin-algs.html#section-33"><i class="fa fa-check"></i><b>2.57</b> [1] 0.8329315</a></li>
<li class="chapter" data-level="2.58" data-path="lin-algs.html"><a href="lin-algs.html#section-34"><i class="fa fa-check"></i><b>2.58</b> [1] 12.32936</a></li>
<li class="chapter" data-level="2.59" data-path="lin-algs.html"><a href="lin-algs.html#section-35"><i class="fa fa-check"></i><b>2.59</b> [1] -130.3349</a></li>
<li class="chapter" data-level="2.60" data-path="lin-algs.html"><a href="lin-algs.html#preds"><i class="fa fa-check"></i><b>2.60</b> preds</a></li>
<li class="chapter" data-level="2.61" data-path="lin-algs.html"><a href="lin-algs.html#section-36"><i class="fa fa-check"></i><b>2.61</b> 0 1</a></li>
<li class="chapter" data-level="2.62" data-path="lin-algs.html"><a href="lin-algs.html#section-37"><i class="fa fa-check"></i><b>2.62</b> 0 20 0</a></li>
<li class="chapter" data-level="2.63" data-path="lin-algs.html"><a href="lin-algs.html#section-38"><i class="fa fa-check"></i><b>2.63</b> 1 0 20</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-lin-algs.html"><a href="non-lin-algs.html"><i class="fa fa-check"></i><b>3</b> Non-linear Algorithms</a><ul>
<li class="chapter" data-level="3.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>3.1</b> Classification and Regression Trees (CART)</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#what-are-cart-models"><i class="fa fa-check"></i>What are CART models?</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#how-does-a-cart-model-learn-from-data"><i class="fa fa-check"></i>How does a CART model learn from data?</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pre-processing-requirements"><i class="fa fa-check"></i>Pre-processing requirements?</a></li>
<li class="chapter" data-level="3.1.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise"><i class="fa fa-check"></i><b>3.1.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="non-lin-algs.html"><a href="non-lin-algs.html#data.frame-951-obs.-of-30-variables"><i class="fa fa-check"></i><b>3.2</b> ‘data.frame’: 951 obs. of 30 variables:</a></li>
<li class="chapter" data-level="3.3" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp001-int-0-0-1-0-0-1-0-1-1-1"><i class="fa fa-check"></i><b>3.3</b> $ FP001 : int 0 0 1 0 0 1 0 1 1 1 …</a></li>
<li class="chapter" data-level="3.4" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp002-int-1-1-1-0-0-0-1-0-0-1"><i class="fa fa-check"></i><b>3.4</b> $ FP002 : int 1 1 1 0 0 0 1 0 0 1 …</a></li>
<li class="chapter" data-level="3.5" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp003-int-0-0-1-1-1-1-0-1-1-1"><i class="fa fa-check"></i><b>3.5</b> $ FP003 : int 0 0 1 1 1 1 0 1 1 1 …</a></li>
<li class="chapter" data-level="3.6" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp004-int-0-1-1-0-1-1-1-1-1-1"><i class="fa fa-check"></i><b>3.6</b> $ FP004 : int 0 1 1 0 1 1 1 1 1 1 …</a></li>
<li class="chapter" data-level="3.7" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp005-int-1-1-1-0-1-0-1-0-0-1"><i class="fa fa-check"></i><b>3.7</b> $ FP005 : int 1 1 1 0 1 0 1 0 0 1 …</a></li>
<li class="chapter" data-level="3.8" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp006-int-0-1-0-0-1-0-0-0-1-1"><i class="fa fa-check"></i><b>3.8</b> $ FP006 : int 0 1 0 0 1 0 0 0 1 1 …</a></li>
<li class="chapter" data-level="3.9" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp007-int-0-1-0-1-0-0-0-1-1-1"><i class="fa fa-check"></i><b>3.9</b> $ FP007 : int 0 1 0 1 0 0 0 1 1 1 …</a></li>
<li class="chapter" data-level="3.10" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp008-int-1-1-1-0-0-0-1-0-0-0"><i class="fa fa-check"></i><b>3.10</b> $ FP008 : int 1 1 1 0 0 0 1 0 0 0 …</a></li>
<li class="chapter" data-level="3.11" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp009-int-0-0-0-0-1-1-1-0-1-0"><i class="fa fa-check"></i><b>3.11</b> $ FP009 : int 0 0 0 0 1 1 1 0 1 0 …</a></li>
<li class="chapter" data-level="3.12" data-path="non-lin-algs.html"><a href="non-lin-algs.html#fp010-int-0-0-1-0-0-0-0-0-0-0"><i class="fa fa-check"></i><b>3.12</b> $ FP010 : int 0 0 1 0 0 0 0 0 0 0 …</a></li>
<li class="chapter" data-level="3.13" data-path="non-lin-algs.html"><a href="non-lin-algs.html#molweight-num-5.34-5.9-5.33-4.92-5.44"><i class="fa fa-check"></i><b>3.13</b> $ MolWeight : num 5.34 5.9 5.33 4.92 5.44 …</a></li>
<li class="chapter" data-level="3.14" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numatoms-num-3.37-3.91-3.53-3.3-3.47"><i class="fa fa-check"></i><b>3.14</b> $ NumAtoms : num 3.37 3.91 3.53 3.3 3.47 …</a></li>
<li class="chapter" data-level="3.15" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numnonhatoms-num-2.83-3.3-2.77-2.4-2.77"><i class="fa fa-check"></i><b>3.15</b> $ NumNonHAtoms : num 2.83 3.3 2.77 2.4 2.77 …</a></li>
<li class="chapter" data-level="3.16" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numbonds-num-3.43-3.97-3.53-3.3-3.47"><i class="fa fa-check"></i><b>3.16</b> $ NumBonds : num 3.43 3.97 3.53 3.3 3.47 …</a></li>
<li class="chapter" data-level="3.17" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numnonhbonds-num-4.01-4.87-3.71-3.08-3.71"><i class="fa fa-check"></i><b>3.17</b> $ NumNonHBonds : num 4.01 4.87 3.71 3.08 3.71 …</a></li>
<li class="chapter" data-level="3.18" data-path="non-lin-algs.html"><a href="non-lin-algs.html#nummultbonds-num-5.26-4.68-3.24-1.38-2.94"><i class="fa fa-check"></i><b>3.18</b> $ NumMultBonds : num 5.26 4.68 3.24 1.38 2.94 …</a></li>
<li class="chapter" data-level="3.19" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numrotbonds-num-0-1.609-1.609-0.693-1.792"><i class="fa fa-check"></i><b>3.19</b> $ NumRotBonds : num 0 1.609 1.609 0.693 1.792 …</a></li>
<li class="chapter" data-level="3.20" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numdblbonds-num-0-0-0.567-0.805-0"><i class="fa fa-check"></i><b>3.20</b> $ NumDblBonds : num 0 0 0.567 0.805 0 …</a></li>
<li class="chapter" data-level="3.21" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numaromaticbonds-num-2.83-2.56-1.95-0-1.95"><i class="fa fa-check"></i><b>3.21</b> $ NumAromaticBonds : num 2.83 2.56 1.95 0 1.95 …</a></li>
<li class="chapter" data-level="3.22" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numhydrogen-num-3.86-5.32-4.73-4.47-4.47"><i class="fa fa-check"></i><b>3.22</b> $ NumHydrogen : num 3.86 5.32 4.73 4.47 4.47 …</a></li>
<li class="chapter" data-level="3.23" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numcarbon-num-4.18-5.09-4.02-3.51-3.32"><i class="fa fa-check"></i><b>3.23</b> $ NumCarbon : num 4.18 5.09 4.02 3.51 3.32 …</a></li>
<li class="chapter" data-level="3.24" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numnitrogen-num-0.585-0.642-0-0-0.694"><i class="fa fa-check"></i><b>3.24</b> $ NumNitrogen : num 0.585 0.642 0 0 0.694 …</a></li>
<li class="chapter" data-level="3.25" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numoxygen-num-0-0.693-1.099-0-0"><i class="fa fa-check"></i><b>3.25</b> $ NumOxygen : num 0 0.693 1.099 0 0 …</a></li>
<li class="chapter" data-level="3.26" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numsulfer-num-0-0.375-0-0-0-0.375-0-0-0-0"><i class="fa fa-check"></i><b>3.26</b> $ NumSulfer : num 0 0.375 0 0 0 0.375 0 0 0 0 …</a></li>
<li class="chapter" data-level="3.27" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numchlorine-num-0-0-0-0-0.375"><i class="fa fa-check"></i><b>3.27</b> $ NumChlorine : num 0 0 0 0 0.375 …</a></li>
<li class="chapter" data-level="3.28" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numhalogen-num-0-0-0-0-0.375"><i class="fa fa-check"></i><b>3.28</b> $ NumHalogen : num 0 0 0 0 0.375 …</a></li>
<li class="chapter" data-level="3.29" data-path="non-lin-algs.html"><a href="non-lin-algs.html#numrings-num-1.386-1.609-0.693-0.693-0.693"><i class="fa fa-check"></i><b>3.29</b> $ NumRings : num 1.386 1.609 0.693 0.693 0.693 …</a></li>
<li class="chapter" data-level="3.30" data-path="non-lin-algs.html"><a href="non-lin-algs.html#hydrophilicfactor-num--1.607--0.441--0.385--2.373--0.071"><i class="fa fa-check"></i><b>3.30</b> $ HydrophilicFactor: num -1.607 -0.441 -0.385 -2.373 -0.071 …</a></li>
<li class="chapter" data-level="3.31" data-path="non-lin-algs.html"><a href="non-lin-algs.html#surfacearea1-num-6.81-9.75-8.25-0-9.91"><i class="fa fa-check"></i><b>3.31</b> $ SurfaceArea1 : num 6.81 9.75 8.25 0 9.91 …</a></li>
<li class="chapter" data-level="3.32" data-path="non-lin-algs.html"><a href="non-lin-algs.html#surfacearea2-num-6.81-12.03-8.25-0-9.91"><i class="fa fa-check"></i><b>3.32</b> $ SurfaceArea2 : num 6.81 12.03 8.25 0 9.91 …</a></li>
<li class="chapter" data-level="3.33" data-path="non-lin-algs.html"><a href="non-lin-algs.html#num-1951--3.97--3.98--3.99--4--4.06--4.08--4.08--4.1--4.1--4.11"><i class="fa fa-check"></i><b>3.33</b> num [1:951] -3.97 -3.98 -3.99 -4 -4.06 -4.08 -4.08 -4.1 -4.1 -4.11 …</a></li>
<li class="chapter" data-level="3.34" data-path="non-lin-algs.html"><a href="non-lin-algs.html#maxdepth-rmse-rsquared-mae-rmsesd-rsquaredsd-maesd"><i class="fa fa-check"></i><b>3.34</b> maxdepth RMSE Rsquared MAE RMSESD RsquaredSD MAESD</a></li>
<li class="chapter" data-level="3.35" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-39"><i class="fa fa-check"></i><b>3.35</b> 1 1 1.617667 0.3745252 1.2657915 0.11511437 0.05777279 0.08191460</a></li>
<li class="chapter" data-level="3.36" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-40"><i class="fa fa-check"></i><b>3.36</b> 2 2 1.433114 0.5067404 1.1326186 0.07599686 0.04909341 0.04940391</a></li>
<li class="chapter" data-level="3.37" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-41"><i class="fa fa-check"></i><b>3.37</b> 3 3 1.357672 0.5568291 1.0657348 0.07354389 0.05231774 0.06091190</a></li>
<li class="chapter" data-level="3.38" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-42"><i class="fa fa-check"></i><b>3.38</b> 4 4 1.263596 0.6166997 0.9974476 0.10201869 0.05547696 0.07947602</a></li>
<li class="chapter" data-level="3.39" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-43"><i class="fa fa-check"></i><b>3.39</b> 5 5 1.192831 0.6581800 0.9429124 0.11324197 0.05669830 0.08594278</a></li>
<li class="chapter" data-level="3.40" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-44"><i class="fa fa-check"></i><b>3.40</b> 6 6 1.142654 0.6853056 0.9009065 0.10585813 0.05990671 0.08607556</a></li>
<li class="chapter" data-level="3.41" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-45"><i class="fa fa-check"></i><b>3.41</b> 7 7 1.111858 0.7020728 0.8707216 0.10580483 0.06389863 0.08126706</a></li>
<li class="chapter" data-level="3.42" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-46"><i class="fa fa-check"></i><b>3.42</b> 8 8 1.094535 0.7110088 0.8545809 0.11400541 0.06474333 0.09512021</a></li>
<li class="chapter" data-level="3.43" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-47"><i class="fa fa-check"></i><b>3.43</b> 9 9 1.091880 0.7116190 0.8465921 0.11938842 0.06737339 0.10068304</a></li>
<li class="chapter" data-level="3.44" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-48"><i class="fa fa-check"></i><b>3.44</b> 10 10 1.068799 0.7236716 0.8232469 0.12842861 0.07102897 0.10641491</a></li>
<li class="chapter" data-level="3.45" data-path="non-lin-algs.html"><a href="non-lin-algs.html#cp-nsplit-rel-error-xerror-xstd"><i class="fa fa-check"></i><b>3.45</b> CP nsplit rel error xerror xstd</a></li>
<li class="chapter" data-level="3.46" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-49"><i class="fa fa-check"></i><b>3.46</b> 1 0.37300506 0 1.0000000 1.0010223 0.05357024</a></li>
<li class="chapter" data-level="3.47" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-50"><i class="fa fa-check"></i><b>3.47</b> 2 0.13770014 1 0.6269949 0.6314019 0.03143820</a></li>
<li class="chapter" data-level="3.48" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-51"><i class="fa fa-check"></i><b>3.48</b> 3 0.06971510 2 0.4892948 0.4945930 0.02321245</a></li>
<li class="chapter" data-level="3.49" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-52"><i class="fa fa-check"></i><b>3.49</b> 4 0.06180269 3 0.4195797 0.4434574 0.02133679</a></li>
<li class="chapter" data-level="3.50" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-53"><i class="fa fa-check"></i><b>3.50</b> 5 0.04729111 4 0.3577770 0.3838988 0.01904376</a></li>
<li class="chapter" data-level="3.51" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-54"><i class="fa fa-check"></i><b>3.51</b> 6 0.02650301 5 0.3104859 0.3514391 0.01837681</a></li>
<li class="chapter" data-level="3.52" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-55"><i class="fa fa-check"></i><b>3.52</b> 7 0.01789274 6 0.2839829 0.3062709 0.01570413</a></li>
<li class="chapter" data-level="3.53" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-56"><i class="fa fa-check"></i><b>3.53</b> 8 0.01553523 7 0.2660901 0.2989517 0.01566820</a></li>
<li class="chapter" data-level="3.54" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-57"><i class="fa fa-check"></i><b>3.54</b> 9 0.01178134 8 0.2505549 0.2910022 0.01551438</a></li>
<li class="chapter" data-level="3.55" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-58"><i class="fa fa-check"></i><b>3.55</b> 10 0.01150195 9 0.2387736 0.2879867 0.01543448</a></li>
<li class="chapter" data-level="3.56" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-59"><i class="fa fa-check"></i><b>3.56</b> 11 0.01000000 10 0.2272716 0.2761810 0.01525549</a></li>
<li class="chapter" data-level="3.57" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-60"><i class="fa fa-check"></i><b>3.57</b> 9 10 11</a></li>
<li class="chapter" data-level="3.58" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-61"><i class="fa fa-check"></i><b>3.58</b> 9 10 11</a></li>
<li class="chapter" data-level="3.59" data-path="non-lin-algs.html"><a href="non-lin-algs.html#data.frame-311-obs.-of-9-variables"><i class="fa fa-check"></i><b>3.59</b> ‘data.frame’: 311 obs. of 9 variables:</a></li>
<li class="chapter" data-level="3.60" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pregnant-int-1-0-2-5-0-1-1-3-11-10"><i class="fa fa-check"></i><b>3.60</b> $ pregnant: int 1 0 2 5 0 1 1 3 11 10 …</a></li>
<li class="chapter" data-level="3.61" data-path="non-lin-algs.html"><a href="non-lin-algs.html#glucose-int-89-137-197-166-118-103-115-126-143-125"><i class="fa fa-check"></i><b>3.61</b> $ glucose : int 89 137 197 166 118 103 115 126 143 125 …</a></li>
<li class="chapter" data-level="3.62" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pressure-int-66-40-70-72-84-30-70-88-94-70"><i class="fa fa-check"></i><b>3.62</b> $ pressure: int 66 40 70 72 84 30 70 88 94 70 …</a></li>
<li class="chapter" data-level="3.63" data-path="non-lin-algs.html"><a href="non-lin-algs.html#triceps-int-23-35-45-19-47-38-30-41-33-26"><i class="fa fa-check"></i><b>3.63</b> $ triceps : int 23 35 45 19 47 38 30 41 33 26 …</a></li>
<li class="chapter" data-level="3.64" data-path="non-lin-algs.html"><a href="non-lin-algs.html#insulin-int-94-168-543-175-230-83-96-235-146-115"><i class="fa fa-check"></i><b>3.64</b> $ insulin : int 94 168 543 175 230 83 96 235 146 115 …</a></li>
<li class="chapter" data-level="3.65" data-path="non-lin-algs.html"><a href="non-lin-algs.html#mass-num-28.1-43.1-30.5-25.8-45.8-43.3-34.6-39.3-36.6-31.1"><i class="fa fa-check"></i><b>3.65</b> $ mass : num 28.1 43.1 30.5 25.8 45.8 43.3 34.6 39.3 36.6 31.1 …</a></li>
<li class="chapter" data-level="3.66" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pedigree-num-0.167-2.288-0.158-0.587-0.551"><i class="fa fa-check"></i><b>3.66</b> $ pedigree: num 0.167 2.288 0.158 0.587 0.551 …</a></li>
<li class="chapter" data-level="3.67" data-path="non-lin-algs.html"><a href="non-lin-algs.html#age-int-21-33-53-51-31-33-32-27-51-41"><i class="fa fa-check"></i><b>3.67</b> $ age : int 21 33 53 51 31 33 32 27 51 41 …</a></li>
<li class="chapter" data-level="3.68" data-path="non-lin-algs.html"><a href="non-lin-algs.html#diabetes-factor-w-2-levels-negpos-1-2-2-2-2-1-2-1-2-2"><i class="fa fa-check"></i><b>3.68</b> $ diabetes: Factor w/ 2 levels “neg”,“pos”: 1 2 2 2 2 1 2 1 2 2 …</a></li>
<li class="chapter" data-level="3.69" data-path="non-lin-algs.html"><a href="non-lin-algs.html#cart"><i class="fa fa-check"></i><b>3.69</b> CART</a></li>
<li class="chapter" data-level="3.70" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-62"><i class="fa fa-check"></i><b>3.70</b> </a></li>
<li class="chapter" data-level="3.71" data-path="non-lin-algs.html"><a href="non-lin-algs.html#samples"><i class="fa fa-check"></i><b>3.71</b> 311 samples</a></li>
<li class="chapter" data-level="3.72" data-path="non-lin-algs.html"><a href="non-lin-algs.html#predictor"><i class="fa fa-check"></i><b>3.72</b> 8 predictor</a></li>
<li class="chapter" data-level="3.73" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classes-neg-pos"><i class="fa fa-check"></i><b>3.73</b> 2 classes: ‘neg’, ‘pos’</a></li>
<li class="chapter" data-level="3.74" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-63"><i class="fa fa-check"></i><b>3.74</b> </a></li>
<li class="chapter" data-level="3.75" data-path="non-lin-algs.html"><a href="non-lin-algs.html#no-pre-processing"><i class="fa fa-check"></i><b>3.75</b> No pre-processing</a></li>
<li class="chapter" data-level="3.76" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-cross-validated-10-fold-repeated-3-times"><i class="fa fa-check"></i><b>3.76</b> Resampling: Cross-Validated (10 fold, repeated 3 times)</a></li>
<li class="chapter" data-level="3.77" data-path="non-lin-algs.html"><a href="non-lin-algs.html#summary-of-sample-sizes-280-280-280-280-280-280"><i class="fa fa-check"></i><b>3.77</b> Summary of sample sizes: 280, 280, 280, 280, 280, 280, …</a></li>
<li class="chapter" data-level="3.78" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-results-across-tuning-parameters"><i class="fa fa-check"></i><b>3.78</b> Resampling results across tuning parameters:</a></li>
<li class="chapter" data-level="3.79" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-64"><i class="fa fa-check"></i><b>3.79</b> </a></li>
<li class="chapter" data-level="3.80" data-path="non-lin-algs.html"><a href="non-lin-algs.html#cp-accuracy-kappa"><i class="fa fa-check"></i><b>3.80</b> cp Accuracy Kappa</a></li>
<li class="chapter" data-level="3.81" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-65"><i class="fa fa-check"></i><b>3.81</b> 0.00000000 0.7790703 0.4994923</a></li>
<li class="chapter" data-level="3.82" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-66"><i class="fa fa-check"></i><b>3.82</b> 0.03219107 0.7740995 0.4937550</a></li>
<li class="chapter" data-level="3.83" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-67"><i class="fa fa-check"></i><b>3.83</b> 0.06438214 0.7699731 0.4670725</a></li>
<li class="chapter" data-level="3.84" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-68"><i class="fa fa-check"></i><b>3.84</b> 0.09657321 0.7580735 0.4369132</a></li>
<li class="chapter" data-level="3.85" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-69"><i class="fa fa-check"></i><b>3.85</b> 0.12876428 0.7591151 0.4401497</a></li>
<li class="chapter" data-level="3.86" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-70"><i class="fa fa-check"></i><b>3.86</b> 0.16095535 0.7410013 0.4188441</a></li>
<li class="chapter" data-level="3.87" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-71"><i class="fa fa-check"></i><b>3.87</b> 0.19314642 0.7420430 0.4219648</a></li>
<li class="chapter" data-level="3.88" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-72"><i class="fa fa-check"></i><b>3.88</b> 0.22533749 0.7420430 0.4219648</a></li>
<li class="chapter" data-level="3.89" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-73"><i class="fa fa-check"></i><b>3.89</b> 0.25752856 0.7420430 0.4219648</a></li>
<li class="chapter" data-level="3.90" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-74"><i class="fa fa-check"></i><b>3.90</b> 0.28971963 0.7150448 0.3111903</a></li>
<li class="chapter" data-level="3.91" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-75"><i class="fa fa-check"></i><b>3.91</b> </a></li>
<li class="chapter" data-level="3.92" data-path="non-lin-algs.html"><a href="non-lin-algs.html#accuracy-was-used-to-select-the-optimal-model-using-the-largest-value."><i class="fa fa-check"></i><b>3.92</b> Accuracy was used to select the optimal model using the largest value.</a></li>
<li class="chapter" data-level="3.93" data-path="non-lin-algs.html"><a href="non-lin-algs.html#the-final-value-used-for-the-model-was-cp-0."><i class="fa fa-check"></i><b>3.93</b> The final value used for the model was cp = 0.</a></li>
<li class="chapter" data-level="3.94" data-path="non-lin-algs.html"><a href="non-lin-algs.html#cart-1"><i class="fa fa-check"></i><b>3.94</b> CART</a></li>
<li class="chapter" data-level="3.95" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-76"><i class="fa fa-check"></i><b>3.95</b> </a></li>
<li class="chapter" data-level="3.96" data-path="non-lin-algs.html"><a href="non-lin-algs.html#samples-1"><i class="fa fa-check"></i><b>3.96</b> 311 samples</a></li>
<li class="chapter" data-level="3.97" data-path="non-lin-algs.html"><a href="non-lin-algs.html#predictor-1"><i class="fa fa-check"></i><b>3.97</b> 8 predictor</a></li>
<li class="chapter" data-level="3.98" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classes-neg-pos-1"><i class="fa fa-check"></i><b>3.98</b> 2 classes: ‘neg’, ‘pos’</a></li>
<li class="chapter" data-level="3.99" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-77"><i class="fa fa-check"></i><b>3.99</b> </a></li>
<li class="chapter" data-level="3.100" data-path="non-lin-algs.html"><a href="non-lin-algs.html#no-pre-processing-1"><i class="fa fa-check"></i><b>3.100</b> No pre-processing</a></li>
<li class="chapter" data-level="3.101" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-cross-validated-10-fold-repeated-3-times-1"><i class="fa fa-check"></i><b>3.101</b> Resampling: Cross-Validated (10 fold, repeated 3 times)</a></li>
<li class="chapter" data-level="3.102" data-path="non-lin-algs.html"><a href="non-lin-algs.html#summary-of-sample-sizes-280-280-280-280-280-280-1"><i class="fa fa-check"></i><b>3.102</b> Summary of sample sizes: 280, 280, 280, 280, 280, 280, …</a></li>
<li class="chapter" data-level="3.103" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-results-across-tuning-parameters-1"><i class="fa fa-check"></i><b>3.103</b> Resampling results across tuning parameters:</a></li>
<li class="chapter" data-level="3.104" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-78"><i class="fa fa-check"></i><b>3.104</b> </a></li>
<li class="chapter" data-level="3.105" data-path="non-lin-algs.html"><a href="non-lin-algs.html#cp-accuracy-kappa-1"><i class="fa fa-check"></i><b>3.105</b> cp Accuracy Kappa</a></li>
<li class="chapter" data-level="3.106" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-79"><i class="fa fa-check"></i><b>3.106</b> 0.00000000 0.7768907 0.5019724</a></li>
<li class="chapter" data-level="3.107" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-80"><i class="fa fa-check"></i><b>3.107</b> 0.03219107 0.7720542 0.4896788</a></li>
<li class="chapter" data-level="3.108" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-81"><i class="fa fa-check"></i><b>3.108</b> 0.06438214 0.7731340 0.4906999</a></li>
<li class="chapter" data-level="3.109" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-82"><i class="fa fa-check"></i><b>3.109</b> 0.09657321 0.7430847 0.4352926</a></li>
<li class="chapter" data-level="3.110" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-83"><i class="fa fa-check"></i><b>3.110</b> 0.12876428 0.7441263 0.4385291</a></li>
<li class="chapter" data-level="3.111" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-84"><i class="fa fa-check"></i><b>3.111</b> 0.16095535 0.7366644 0.4268724</a></li>
<li class="chapter" data-level="3.112" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-85"><i class="fa fa-check"></i><b>3.112</b> 0.19314642 0.7377061 0.4299930</a></li>
<li class="chapter" data-level="3.113" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-86"><i class="fa fa-check"></i><b>3.113</b> 0.22533749 0.7377061 0.4299930</a></li>
<li class="chapter" data-level="3.114" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-87"><i class="fa fa-check"></i><b>3.114</b> 0.25752856 0.7377061 0.4299930</a></li>
<li class="chapter" data-level="3.115" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-88"><i class="fa fa-check"></i><b>3.115</b> 0.28971963 0.6912097 0.2398796</a></li>
<li class="chapter" data-level="3.116" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-89"><i class="fa fa-check"></i><b>3.116</b> </a></li>
<li class="chapter" data-level="3.117" data-path="non-lin-algs.html"><a href="non-lin-algs.html#accuracy-was-used-to-select-the-optimal-model-using-the-largest-value.-1"><i class="fa fa-check"></i><b>3.117</b> Accuracy was used to select the optimal model using the largest value.</a></li>
<li class="chapter" data-level="3.118" data-path="non-lin-algs.html"><a href="non-lin-algs.html#the-final-value-used-for-the-model-was-cp-0.-1"><i class="fa fa-check"></i><b>3.118</b> The final value used for the model was cp = 0.</a></li>
<li class="chapter" data-level="3.119" data-path="non-lin-algs.html"><a href="non-lin-algs.html#naive-bayes"><i class="fa fa-check"></i><b>3.119</b> Naive Bayes</a><ul>
<li class="chapter" data-level="3.119.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-1"><i class="fa fa-check"></i><b>3.119.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.120" data-path="non-lin-algs.html"><a href="non-lin-algs.html#confusion-matrix-and-statistics"><i class="fa fa-check"></i><b>3.120</b> Confusion Matrix and Statistics</a></li>
<li class="chapter" data-level="3.121" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-90"><i class="fa fa-check"></i><b>3.121</b> </a></li>
<li class="chapter" data-level="3.122" data-path="non-lin-algs.html"><a href="non-lin-algs.html#reference"><i class="fa fa-check"></i><b>3.122</b> Reference</a></li>
<li class="chapter" data-level="3.123" data-path="non-lin-algs.html"><a href="non-lin-algs.html#prediction-neg-pos"><i class="fa fa-check"></i><b>3.123</b> Prediction neg pos</a></li>
<li class="chapter" data-level="3.124" data-path="non-lin-algs.html"><a href="non-lin-algs.html#neg-169-35"><i class="fa fa-check"></i><b>3.124</b> neg 169 35</a></li>
<li class="chapter" data-level="3.125" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pos-35-72"><i class="fa fa-check"></i><b>3.125</b> pos 35 72</a></li>
<li class="chapter" data-level="3.126" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-91"><i class="fa fa-check"></i><b>3.126</b> </a></li>
<li class="chapter" data-level="3.127" data-path="non-lin-algs.html"><a href="non-lin-algs.html#accuracy-0.7749"><i class="fa fa-check"></i><b>3.127</b> Accuracy : 0.7749</a></li>
<li class="chapter" data-level="3.128" data-path="non-lin-algs.html"><a href="non-lin-algs.html#ci-0.7244-0.8201"><i class="fa fa-check"></i><b>3.128</b> 95% CI : (0.7244, 0.8201)</a></li>
<li class="chapter" data-level="3.129" data-path="non-lin-algs.html"><a href="non-lin-algs.html#no-information-rate-0.6559"><i class="fa fa-check"></i><b>3.129</b> No Information Rate : 0.6559</a></li>
<li class="chapter" data-level="3.130" data-path="non-lin-algs.html"><a href="non-lin-algs.html#p-value-acc-nir-3.352e-06"><i class="fa fa-check"></i><b>3.130</b> P-Value [Acc &gt; NIR] : 3.352e-06</a></li>
<li class="chapter" data-level="3.131" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-92"><i class="fa fa-check"></i><b>3.131</b> </a></li>
<li class="chapter" data-level="3.132" data-path="non-lin-algs.html"><a href="non-lin-algs.html#kappa-0.5013"><i class="fa fa-check"></i><b>3.132</b> Kappa : 0.5013</a></li>
<li class="chapter" data-level="3.133" data-path="non-lin-algs.html"><a href="non-lin-algs.html#mcnemars-test-p-value-1"><i class="fa fa-check"></i><b>3.133</b> Mcnemar’s Test P-Value : 1</a></li>
<li class="chapter" data-level="3.134" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-93"><i class="fa fa-check"></i><b>3.134</b> </a></li>
<li class="chapter" data-level="3.135" data-path="non-lin-algs.html"><a href="non-lin-algs.html#sensitivity-0.8284"><i class="fa fa-check"></i><b>3.135</b> Sensitivity : 0.8284</a></li>
<li class="chapter" data-level="3.136" data-path="non-lin-algs.html"><a href="non-lin-algs.html#specificity-0.6729"><i class="fa fa-check"></i><b>3.136</b> Specificity : 0.6729</a></li>
<li class="chapter" data-level="3.137" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pos-pred-value-0.8284"><i class="fa fa-check"></i><b>3.137</b> Pos Pred Value : 0.8284</a></li>
<li class="chapter" data-level="3.138" data-path="non-lin-algs.html"><a href="non-lin-algs.html#neg-pred-value-0.6729"><i class="fa fa-check"></i><b>3.138</b> Neg Pred Value : 0.6729</a></li>
<li class="chapter" data-level="3.139" data-path="non-lin-algs.html"><a href="non-lin-algs.html#prevalence-0.6559"><i class="fa fa-check"></i><b>3.139</b> Prevalence : 0.6559</a></li>
<li class="chapter" data-level="3.140" data-path="non-lin-algs.html"><a href="non-lin-algs.html#detection-rate-0.5434"><i class="fa fa-check"></i><b>3.140</b> Detection Rate : 0.5434</a></li>
<li class="chapter" data-level="3.141" data-path="non-lin-algs.html"><a href="non-lin-algs.html#detection-prevalence-0.6559"><i class="fa fa-check"></i><b>3.141</b> Detection Prevalence : 0.6559</a></li>
<li class="chapter" data-level="3.142" data-path="non-lin-algs.html"><a href="non-lin-algs.html#balanced-accuracy-0.7507"><i class="fa fa-check"></i><b>3.142</b> Balanced Accuracy : 0.7507</a></li>
<li class="chapter" data-level="3.143" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-94"><i class="fa fa-check"></i><b>3.143</b> </a></li>
<li class="chapter" data-level="3.144" data-path="non-lin-algs.html"><a href="non-lin-algs.html#positive-class-neg"><i class="fa fa-check"></i><b>3.144</b> ‘Positive’ Class : neg</a></li>
<li class="chapter" data-level="3.145" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-95"><i class="fa fa-check"></i><b>3.145</b> </a></li>
<li class="chapter" data-level="3.146" data-path="non-lin-algs.html"><a href="non-lin-algs.html#k-nearest-neigbors"><i class="fa fa-check"></i><b>3.146</b> k-Nearest Neigbors</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#curse-of-dimensionality"><i class="fa fa-check"></i>Curse of Dimensionality</a></li>
<li class="chapter" data-level="3.146.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-2"><i class="fa fa-check"></i><b>3.146.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.147" data-path="non-lin-algs.html"><a href="non-lin-algs.html#nearest-neighbor-regression-model"><i class="fa fa-check"></i><b>3.147</b> 4-nearest neighbor regression model</a></li>
<li class="chapter" data-level="3.148" data-path="non-lin-algs.html"><a href="non-lin-algs.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.148</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="3.149" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-96"><i class="fa fa-check"></i><b>3.149</b> </a></li>
<li class="chapter" data-level="3.150" data-path="non-lin-algs.html"><a href="non-lin-algs.html#samples-2"><i class="fa fa-check"></i><b>3.150</b> 311 samples</a></li>
<li class="chapter" data-level="3.151" data-path="non-lin-algs.html"><a href="non-lin-algs.html#predictor-2"><i class="fa fa-check"></i><b>3.151</b> 8 predictor</a></li>
<li class="chapter" data-level="3.152" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classes-neg-pos-2"><i class="fa fa-check"></i><b>3.152</b> 2 classes: ‘neg’, ‘pos’</a></li>
<li class="chapter" data-level="3.153" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-97"><i class="fa fa-check"></i><b>3.153</b> </a></li>
<li class="chapter" data-level="3.154" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pre-processing-centered-8-scaled-8"><i class="fa fa-check"></i><b>3.154</b> Pre-processing: centered (8), scaled (8)</a></li>
<li class="chapter" data-level="3.155" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-cross-validated-10-fold"><i class="fa fa-check"></i><b>3.155</b> Resampling: Cross-Validated (10 fold)</a></li>
<li class="chapter" data-level="3.156" data-path="non-lin-algs.html"><a href="non-lin-algs.html#summary-of-sample-sizes-280-281-280-279-280-281"><i class="fa fa-check"></i><b>3.156</b> Summary of sample sizes: 280, 281, 280, 279, 280, 281, …</a></li>
<li class="chapter" data-level="3.157" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-results-across-tuning-parameters-2"><i class="fa fa-check"></i><b>3.157</b> Resampling results across tuning parameters:</a></li>
<li class="chapter" data-level="3.158" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-98"><i class="fa fa-check"></i><b>3.158</b> </a></li>
<li class="chapter" data-level="3.159" data-path="non-lin-algs.html"><a href="non-lin-algs.html#k-roc-sens-spec"><i class="fa fa-check"></i><b>3.159</b> k ROC Sens Spec</a></li>
<li class="chapter" data-level="3.160" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-99"><i class="fa fa-check"></i><b>3.160</b> 1 0.6758874 0.7990476 0.5527273</a></li>
<li class="chapter" data-level="3.161" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-100"><i class="fa fa-check"></i><b>3.161</b> 2 0.7472781 0.7840476 0.5318182</a></li>
<li class="chapter" data-level="3.162" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-101"><i class="fa fa-check"></i><b>3.162</b> 3 0.7854405 0.8530952 0.5327273</a></li>
<li class="chapter" data-level="3.163" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-102"><i class="fa fa-check"></i><b>3.163</b> 4 0.7962013 0.8435714 0.5709091</a></li>
<li class="chapter" data-level="3.164" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-103"><i class="fa fa-check"></i><b>3.164</b> 5 0.7963950 0.8585714 0.5700000</a></li>
<li class="chapter" data-level="3.165" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-104"><i class="fa fa-check"></i><b>3.165</b> 6 0.7987013 0.8733333 0.5800000</a></li>
<li class="chapter" data-level="3.166" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-105"><i class="fa fa-check"></i><b>3.166</b> 7 0.8115682 0.8785714 0.5681818</a></li>
<li class="chapter" data-level="3.167" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-106"><i class="fa fa-check"></i><b>3.167</b> 8 0.8184437 0.8978571 0.5218182</a></li>
<li class="chapter" data-level="3.168" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-107"><i class="fa fa-check"></i><b>3.168</b> 9 0.8219935 0.8926190 0.5045455</a></li>
<li class="chapter" data-level="3.169" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-108"><i class="fa fa-check"></i><b>3.169</b> 10 0.8193268 0.8926190 0.5127273</a></li>
<li class="chapter" data-level="3.170" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-109"><i class="fa fa-check"></i><b>3.170</b> 11 0.8269091 0.8780952 0.5318182</a></li>
<li class="chapter" data-level="3.171" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-110"><i class="fa fa-check"></i><b>3.171</b> 12 0.8344470 0.8876190 0.4945455</a></li>
<li class="chapter" data-level="3.172" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-111"><i class="fa fa-check"></i><b>3.172</b> 13 0.8369232 0.8973810 0.4936364</a></li>
<li class="chapter" data-level="3.173" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-112"><i class="fa fa-check"></i><b>3.173</b> 14 0.8384621 0.8971429 0.4745455</a></li>
<li class="chapter" data-level="3.174" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-113"><i class="fa fa-check"></i><b>3.174</b> 15 0.8404080 0.8976190 0.4936364</a></li>
<li class="chapter" data-level="3.175" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-114"><i class="fa fa-check"></i><b>3.175</b> 16 0.8378268 0.8973810 0.5036364</a></li>
<li class="chapter" data-level="3.176" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-115"><i class="fa fa-check"></i><b>3.176</b> 17 0.8421396 0.9121429 0.4663636</a></li>
<li class="chapter" data-level="3.177" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-116"><i class="fa fa-check"></i><b>3.177</b> 18 0.8384405 0.9119048 0.4745455</a></li>
<li class="chapter" data-level="3.178" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-117"><i class="fa fa-check"></i><b>3.178</b> 19 0.8382392 0.9019048 0.4745455</a></li>
<li class="chapter" data-level="3.179" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-118"><i class="fa fa-check"></i><b>3.179</b> 20 0.8325335 0.9019048 0.4936364</a></li>
<li class="chapter" data-level="3.180" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-119"><i class="fa fa-check"></i><b>3.180</b> 21 0.8388268 0.9119048 0.5018182</a></li>
<li class="chapter" data-level="3.181" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-120"><i class="fa fa-check"></i><b>3.181</b> 22 0.8414740 0.9119048 0.4845455</a></li>
<li class="chapter" data-level="3.182" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-121"><i class="fa fa-check"></i><b>3.182</b> 23 0.8419794 0.9166667 0.4836364</a></li>
<li class="chapter" data-level="3.183" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-122"><i class="fa fa-check"></i><b>3.183</b> 24 0.8454058 0.9169048 0.4836364</a></li>
<li class="chapter" data-level="3.184" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-123"><i class="fa fa-check"></i><b>3.184</b> 25 0.8452814 0.9169048 0.4636364</a></li>
<li class="chapter" data-level="3.185" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-124"><i class="fa fa-check"></i><b>3.185</b> 26 0.8434935 0.9169048 0.4563636</a></li>
<li class="chapter" data-level="3.186" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-125"><i class="fa fa-check"></i><b>3.186</b> 27 0.8491331 0.9216667 0.4554545</a></li>
<li class="chapter" data-level="3.187" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-126"><i class="fa fa-check"></i><b>3.187</b> 28 0.8474957 0.9314286 0.4645455</a></li>
<li class="chapter" data-level="3.188" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-127"><i class="fa fa-check"></i><b>3.188</b> 29 0.8446385 0.9216667 0.4363636</a></li>
<li class="chapter" data-level="3.189" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-128"><i class="fa fa-check"></i><b>3.189</b> 30 0.8437154 0.9266667 0.4363636</a></li>
<li class="chapter" data-level="3.190" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-129"><i class="fa fa-check"></i><b>3.190</b> 31 0.8392987 0.9266667 0.4263636</a></li>
<li class="chapter" data-level="3.191" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-130"><i class="fa fa-check"></i><b>3.191</b> 32 0.8399816 0.9216667 0.4272727</a></li>
<li class="chapter" data-level="3.192" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-131"><i class="fa fa-check"></i><b>3.192</b> 33 0.8390368 0.9266667 0.4272727</a></li>
<li class="chapter" data-level="3.193" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-132"><i class="fa fa-check"></i><b>3.193</b> 34 0.8381483 0.9266667 0.4190909</a></li>
<li class="chapter" data-level="3.194" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-133"><i class="fa fa-check"></i><b>3.194</b> 35 0.8404892 0.9316667 0.4281818</a></li>
<li class="chapter" data-level="3.195" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-134"><i class="fa fa-check"></i><b>3.195</b> 36 0.8392532 0.9316667 0.4381818</a></li>
<li class="chapter" data-level="3.196" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-135"><i class="fa fa-check"></i><b>3.196</b> 37 0.8412446 0.9269048 0.4281818</a></li>
<li class="chapter" data-level="3.197" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-136"><i class="fa fa-check"></i><b>3.197</b> 38 0.8404448 0.9319048 0.4281818</a></li>
<li class="chapter" data-level="3.198" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-137"><i class="fa fa-check"></i><b>3.198</b> 39 0.8436937 0.9466667 0.4281818</a></li>
<li class="chapter" data-level="3.199" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-138"><i class="fa fa-check"></i><b>3.199</b> 40 0.8449589 0.9416667 0.4281818</a></li>
<li class="chapter" data-level="3.200" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-139"><i class="fa fa-check"></i><b>3.200</b> 41 0.8423431 0.9366667 0.4381818</a></li>
<li class="chapter" data-level="3.201" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-140"><i class="fa fa-check"></i><b>3.201</b> 42 0.8405693 0.9366667 0.4372727</a></li>
<li class="chapter" data-level="3.202" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-141"><i class="fa fa-check"></i><b>3.202</b> 43 0.8415855 0.9464286 0.4372727</a></li>
<li class="chapter" data-level="3.203" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-142"><i class="fa fa-check"></i><b>3.203</b> 44 0.8449123 0.9561905 0.4463636</a></li>
<li class="chapter" data-level="3.204" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-143"><i class="fa fa-check"></i><b>3.204</b> 45 0.8451190 0.9511905 0.4281818</a></li>
<li class="chapter" data-level="3.205" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-144"><i class="fa fa-check"></i><b>3.205</b> 46 0.8455054 0.9416667 0.4372727</a></li>
<li class="chapter" data-level="3.206" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-145"><i class="fa fa-check"></i><b>3.206</b> 47 0.8452846 0.9464286 0.4281818</a></li>
<li class="chapter" data-level="3.207" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-146"><i class="fa fa-check"></i><b>3.207</b> 48 0.8459361 0.9464286 0.4372727</a></li>
<li class="chapter" data-level="3.208" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-147"><i class="fa fa-check"></i><b>3.208</b> 49 0.8466537 0.9414286 0.4181818</a></li>
<li class="chapter" data-level="3.209" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-148"><i class="fa fa-check"></i><b>3.209</b> 50 0.8445725 0.9514286 0.4090909</a></li>
<li class="chapter" data-level="3.210" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-149"><i class="fa fa-check"></i><b>3.210</b> </a></li>
<li class="chapter" data-level="3.211" data-path="non-lin-algs.html"><a href="non-lin-algs.html#roc-was-used-to-select-the-optimal-model-using-the-largest-value."><i class="fa fa-check"></i><b>3.211</b> ROC was used to select the optimal model using the largest value.</a></li>
<li class="chapter" data-level="3.212" data-path="non-lin-algs.html"><a href="non-lin-algs.html#the-final-value-used-for-the-model-was-k-27."><i class="fa fa-check"></i><b>3.212</b> The final value used for the model was k = 27.</a></li>
<li class="chapter" data-level="3.213" data-path="non-lin-algs.html"><a href="non-lin-algs.html#nearest-neighbor-model"><i class="fa fa-check"></i><b>3.213</b> 27-nearest neighbor model</a></li>
<li class="chapter" data-level="3.214" data-path="non-lin-algs.html"><a href="non-lin-algs.html#training-set-outcome-distribution"><i class="fa fa-check"></i><b>3.214</b> Training set outcome distribution:</a></li>
<li class="chapter" data-level="3.215" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-150"><i class="fa fa-check"></i><b>3.215</b> </a></li>
<li class="chapter" data-level="3.216" data-path="non-lin-algs.html"><a href="non-lin-algs.html#neg-pos"><i class="fa fa-check"></i><b>3.216</b> neg pos</a></li>
<li class="chapter" data-level="3.217" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-151"><i class="fa fa-check"></i><b>3.217</b> 204 107</a></li>
<li class="chapter" data-level="3.218" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machines"><i class="fa fa-check"></i><b>3.218</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#regression-1"><i class="fa fa-check"></i>Regression</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classification-1"><i class="fa fa-check"></i>Classification</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#optimizaton-forumulation"><i class="fa fa-check"></i>Optimizaton Forumulation</a></li>
<li class="chapter" data-level="3.218.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-3"><i class="fa fa-check"></i><b>3.218.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.219" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machines-with-radial-basis-function-kernel"><i class="fa fa-check"></i><b>3.219</b> Support Vector Machines with Radial Basis Function Kernel</a></li>
<li class="chapter" data-level="3.220" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-152"><i class="fa fa-check"></i><b>3.220</b> </a></li>
<li class="chapter" data-level="3.221" data-path="non-lin-algs.html"><a href="non-lin-algs.html#samples-3"><i class="fa fa-check"></i><b>3.221</b> 951 samples</a></li>
<li class="chapter" data-level="3.222" data-path="non-lin-algs.html"><a href="non-lin-algs.html#predictors"><i class="fa fa-check"></i><b>3.222</b> 228 predictors</a></li>
<li class="chapter" data-level="3.223" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-153"><i class="fa fa-check"></i><b>3.223</b> </a></li>
<li class="chapter" data-level="3.224" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pre-processing-centered-228-scaled-228"><i class="fa fa-check"></i><b>3.224</b> Pre-processing: centered (228), scaled (228)</a></li>
<li class="chapter" data-level="3.225" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-cross-validated-10-fold-1"><i class="fa fa-check"></i><b>3.225</b> Resampling: Cross-Validated (10 fold)</a></li>
<li class="chapter" data-level="3.226" data-path="non-lin-algs.html"><a href="non-lin-algs.html#summary-of-sample-sizes-855-856-855-855-858-857"><i class="fa fa-check"></i><b>3.226</b> Summary of sample sizes: 855, 856, 855, 855, 858, 857, …</a></li>
<li class="chapter" data-level="3.227" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-results-across-tuning-parameters-3"><i class="fa fa-check"></i><b>3.227</b> Resampling results across tuning parameters:</a></li>
<li class="chapter" data-level="3.228" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-154"><i class="fa fa-check"></i><b>3.228</b> </a></li>
<li class="chapter" data-level="3.229" data-path="non-lin-algs.html"><a href="non-lin-algs.html#c-rmse-rsquared-mae"><i class="fa fa-check"></i><b>3.229</b> C RMSE Rsquared MAE</a></li>
<li class="chapter" data-level="3.230" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-155"><i class="fa fa-check"></i><b>3.230</b> 0.25 0.8014848 0.8681906 0.6039660</a></li>
<li class="chapter" data-level="3.231" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-156"><i class="fa fa-check"></i><b>3.231</b> 0.50 0.7102286 0.8890663 0.5327464</a></li>
<li class="chapter" data-level="3.232" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-157"><i class="fa fa-check"></i><b>3.232</b> 1.00 0.6613592 0.9000814 0.4934836</a></li>
<li class="chapter" data-level="3.233" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-158"><i class="fa fa-check"></i><b>3.233</b> 2.00 0.6314286 0.9066489 0.4684522</a></li>
<li class="chapter" data-level="3.234" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-159"><i class="fa fa-check"></i><b>3.234</b> 4.00 0.6186151 0.9091987 0.4541152</a></li>
<li class="chapter" data-level="3.235" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-160"><i class="fa fa-check"></i><b>3.235</b> 8.00 0.6064508 0.9127569 0.4457087</a></li>
<li class="chapter" data-level="3.236" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-161"><i class="fa fa-check"></i><b>3.236</b> 16.00 0.6018292 0.9140239 0.4427055</a></li>
<li class="chapter" data-level="3.237" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-162"><i class="fa fa-check"></i><b>3.237</b> 32.00 0.6018878 0.9138726 0.4429424</a></li>
<li class="chapter" data-level="3.238" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-163"><i class="fa fa-check"></i><b>3.238</b> 64.00 0.6007705 0.9141895 0.4423807</a></li>
<li class="chapter" data-level="3.239" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-164"><i class="fa fa-check"></i><b>3.239</b> 128.00 0.5998743 0.9145279 0.4443426</a></li>
<li class="chapter" data-level="3.240" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-165"><i class="fa fa-check"></i><b>3.240</b> 256.00 0.6025174 0.9136982 0.4463239</a></li>
<li class="chapter" data-level="3.241" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-166"><i class="fa fa-check"></i><b>3.241</b> 512.00 0.6039626 0.9132093 0.4469188</a></li>
<li class="chapter" data-level="3.242" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-167"><i class="fa fa-check"></i><b>3.242</b> 1024.00 0.6042640 0.9131080 0.4474508</a></li>
<li class="chapter" data-level="3.243" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-168"><i class="fa fa-check"></i><b>3.243</b> 2048.00 0.6062670 0.9125208 0.4497784</a></li>
<li class="chapter" data-level="3.244" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-169"><i class="fa fa-check"></i><b>3.244</b> </a></li>
<li class="chapter" data-level="3.245" data-path="non-lin-algs.html"><a href="non-lin-algs.html#tuning-parameter-sigma-was-held-constant-at-a-value-of-0.002740343"><i class="fa fa-check"></i><b>3.245</b> Tuning parameter ‘sigma’ was held constant at a value of 0.002740343</a></li>
<li class="chapter" data-level="3.246" data-path="non-lin-algs.html"><a href="non-lin-algs.html#rmse-was-used-to-select-the-optimal-model-using-the-smallest-value."><i class="fa fa-check"></i><b>3.246</b> RMSE was used to select the optimal model using the smallest value.</a></li>
<li class="chapter" data-level="3.247" data-path="non-lin-algs.html"><a href="non-lin-algs.html#the-final-values-used-for-the-model-were-sigma-0.002740343-and-c-128."><i class="fa fa-check"></i><b>3.247</b> The final values used for the model were sigma = 0.002740343 and C = 128.</a></li>
<li class="chapter" data-level="3.248" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machine-object-of-class-ksvm"><i class="fa fa-check"></i><b>3.248</b> Support Vector Machine object of class “ksvm”</a></li>
<li class="chapter" data-level="3.249" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-170"><i class="fa fa-check"></i><b>3.249</b> </a></li>
<li class="chapter" data-level="3.250" data-path="non-lin-algs.html"><a href="non-lin-algs.html#sv-type-eps-svr-regression"><i class="fa fa-check"></i><b>3.250</b> SV type: eps-svr (regression)</a></li>
<li class="chapter" data-level="3.251" data-path="non-lin-algs.html"><a href="non-lin-algs.html#parameter-epsilon-0.1-cost-c-128"><i class="fa fa-check"></i><b>3.251</b> parameter : epsilon = 0.1 cost C = 128</a></li>
<li class="chapter" data-level="3.252" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-171"><i class="fa fa-check"></i><b>3.252</b> </a></li>
<li class="chapter" data-level="3.253" data-path="non-lin-algs.html"><a href="non-lin-algs.html#gaussian-radial-basis-kernel-function."><i class="fa fa-check"></i><b>3.253</b> Gaussian Radial Basis kernel function.</a></li>
<li class="chapter" data-level="3.254" data-path="non-lin-algs.html"><a href="non-lin-algs.html#hyperparameter-sigma-0.0027403433192481"><i class="fa fa-check"></i><b>3.254</b> Hyperparameter : sigma = 0.0027403433192481</a></li>
<li class="chapter" data-level="3.255" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-172"><i class="fa fa-check"></i><b>3.255</b> </a></li>
<li class="chapter" data-level="3.256" data-path="non-lin-algs.html"><a href="non-lin-algs.html#number-of-support-vectors-638"><i class="fa fa-check"></i><b>3.256</b> Number of Support Vectors : 638</a></li>
<li class="chapter" data-level="3.257" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-173"><i class="fa fa-check"></i><b>3.257</b> </a></li>
<li class="chapter" data-level="3.258" data-path="non-lin-algs.html"><a href="non-lin-algs.html#objective-function-value--726.094"><i class="fa fa-check"></i><b>3.258</b> Objective Function Value : -726.094</a></li>
<li class="chapter" data-level="3.259" data-path="non-lin-algs.html"><a href="non-lin-algs.html#training-error-0.009299"><i class="fa fa-check"></i><b>3.259</b> Training error : 0.009299</a></li>
<li class="chapter" data-level="3.260" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machines-with-radial-basis-function-kernel-1"><i class="fa fa-check"></i><b>3.260</b> Support Vector Machines with Radial Basis Function Kernel</a></li>
<li class="chapter" data-level="3.261" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-174"><i class="fa fa-check"></i><b>3.261</b> </a></li>
<li class="chapter" data-level="3.262" data-path="non-lin-algs.html"><a href="non-lin-algs.html#samples-4"><i class="fa fa-check"></i><b>3.262</b> 311 samples</a></li>
<li class="chapter" data-level="3.263" data-path="non-lin-algs.html"><a href="non-lin-algs.html#predictor-3"><i class="fa fa-check"></i><b>3.263</b> 8 predictor</a></li>
<li class="chapter" data-level="3.264" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classes-neg-pos-3"><i class="fa fa-check"></i><b>3.264</b> 2 classes: ‘neg’, ‘pos’</a></li>
<li class="chapter" data-level="3.265" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-175"><i class="fa fa-check"></i><b>3.265</b> </a></li>
<li class="chapter" data-level="3.266" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pre-processing-centered-8-scaled-8-1"><i class="fa fa-check"></i><b>3.266</b> Pre-processing: centered (8), scaled (8)</a></li>
<li class="chapter" data-level="3.267" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-cross-validated-10-fold-2"><i class="fa fa-check"></i><b>3.267</b> Resampling: Cross-Validated (10 fold)</a></li>
<li class="chapter" data-level="3.268" data-path="non-lin-algs.html"><a href="non-lin-algs.html#summary-of-sample-sizes-280-279-279-279-280-280"><i class="fa fa-check"></i><b>3.268</b> Summary of sample sizes: 280, 279, 279, 279, 280, 280, …</a></li>
<li class="chapter" data-level="3.269" data-path="non-lin-algs.html"><a href="non-lin-algs.html#resampling-results-across-tuning-parameters-4"><i class="fa fa-check"></i><b>3.269</b> Resampling results across tuning parameters:</a></li>
<li class="chapter" data-level="3.270" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-176"><i class="fa fa-check"></i><b>3.270</b> </a></li>
<li class="chapter" data-level="3.271" data-path="non-lin-algs.html"><a href="non-lin-algs.html#c-roc-sens-spec"><i class="fa fa-check"></i><b>3.271</b> C ROC Sens Spec</a></li>
<li class="chapter" data-level="3.272" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-177"><i class="fa fa-check"></i><b>3.272</b> 0.0625 0.8434134 0.7795238 0.6945455</a></li>
<li class="chapter" data-level="3.273" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-178"><i class="fa fa-check"></i><b>3.273</b> 0.1250 0.8434134 0.7842857 0.6945455</a></li>
<li class="chapter" data-level="3.274" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-179"><i class="fa fa-check"></i><b>3.274</b> 0.2500 0.8503506 0.8426190 0.6090909</a></li>
<li class="chapter" data-level="3.275" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-180"><i class="fa fa-check"></i><b>3.275</b> 0.5000 0.8476623 0.8573810 0.5909091</a></li>
<li class="chapter" data-level="3.276" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-181"><i class="fa fa-check"></i><b>3.276</b> 1.0000 0.8478203 0.8678571 0.5727273</a></li>
<li class="chapter" data-level="3.277" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-182"><i class="fa fa-check"></i><b>3.277</b> 2.0000 0.8427922 0.8528571 0.5736364</a></li>
<li class="chapter" data-level="3.278" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-183"><i class="fa fa-check"></i><b>3.278</b> 4.0000 0.8400390 0.8626190 0.5154545</a></li>
<li class="chapter" data-level="3.279" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-184"><i class="fa fa-check"></i><b>3.279</b> 8.0000 0.8388355 0.8828571 0.4872727</a></li>
<li class="chapter" data-level="3.280" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-185"><i class="fa fa-check"></i><b>3.280</b> 16.0000 0.8367100 0.9066667 0.4972727</a></li>
<li class="chapter" data-level="3.281" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-186"><i class="fa fa-check"></i><b>3.281</b> </a></li>
<li class="chapter" data-level="3.282" data-path="non-lin-algs.html"><a href="non-lin-algs.html#tuning-parameter-sigma-was-held-constant-at-a-value-of-0.03176525"><i class="fa fa-check"></i><b>3.282</b> Tuning parameter ‘sigma’ was held constant at a value of 0.03176525</a></li>
<li class="chapter" data-level="3.283" data-path="non-lin-algs.html"><a href="non-lin-algs.html#roc-was-used-to-select-the-optimal-model-using-the-largest-value.-1"><i class="fa fa-check"></i><b>3.283</b> ROC was used to select the optimal model using the largest value.</a></li>
<li class="chapter" data-level="3.284" data-path="non-lin-algs.html"><a href="non-lin-algs.html#the-final-values-used-for-the-model-were-sigma-0.03176525-and-c-0.25."><i class="fa fa-check"></i><b>3.284</b> The final values used for the model were sigma = 0.03176525 and C = 0.25.</a></li>
<li class="chapter" data-level="3.285" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machine-object-of-class-ksvm-1"><i class="fa fa-check"></i><b>3.285</b> Support Vector Machine object of class “ksvm”</a></li>
<li class="chapter" data-level="3.286" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-187"><i class="fa fa-check"></i><b>3.286</b> </a></li>
<li class="chapter" data-level="3.287" data-path="non-lin-algs.html"><a href="non-lin-algs.html#sv-type-c-svc-classification"><i class="fa fa-check"></i><b>3.287</b> SV type: C-svc (classification)</a></li>
<li class="chapter" data-level="3.288" data-path="non-lin-algs.html"><a href="non-lin-algs.html#parameter-cost-c-0.25"><i class="fa fa-check"></i><b>3.288</b> parameter : cost C = 0.25</a></li>
<li class="chapter" data-level="3.289" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-188"><i class="fa fa-check"></i><b>3.289</b> </a></li>
<li class="chapter" data-level="3.290" data-path="non-lin-algs.html"><a href="non-lin-algs.html#gaussian-radial-basis-kernel-function.-1"><i class="fa fa-check"></i><b>3.290</b> Gaussian Radial Basis kernel function.</a></li>
<li class="chapter" data-level="3.291" data-path="non-lin-algs.html"><a href="non-lin-algs.html#hyperparameter-sigma-0.0317652466552473"><i class="fa fa-check"></i><b>3.291</b> Hyperparameter : sigma = 0.0317652466552473</a></li>
<li class="chapter" data-level="3.292" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-189"><i class="fa fa-check"></i><b>3.292</b> </a></li>
<li class="chapter" data-level="3.293" data-path="non-lin-algs.html"><a href="non-lin-algs.html#number-of-support-vectors-197"><i class="fa fa-check"></i><b>3.293</b> Number of Support Vectors : 197</a></li>
<li class="chapter" data-level="3.294" data-path="non-lin-algs.html"><a href="non-lin-algs.html#section-190"><i class="fa fa-check"></i><b>3.294</b> </a></li>
<li class="chapter" data-level="3.295" data-path="non-lin-algs.html"><a href="non-lin-algs.html#objective-function-value--43.388"><i class="fa fa-check"></i><b>3.295</b> Objective Function Value : -43.388</a></li>
<li class="chapter" data-level="3.296" data-path="non-lin-algs.html"><a href="non-lin-algs.html#probability-model-included."><i class="fa fa-check"></i><b>3.296</b> Probability model included.</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ens-algs.html"><a href="ens-algs.html"><i class="fa fa-check"></i><b>4</b> Ensemble Algorithms</a><ul>
<li class="chapter" data-level="4.1" data-path="ens-algs.html"><a href="ens-algs.html#bagging"><i class="fa fa-check"></i><b>4.1</b> Bagging</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-1"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ens-algs.html"><a href="ens-algs.html#random-forest"><i class="fa fa-check"></i><b>4.2</b> Random Forest</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-2"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ens-algs.html"><a href="ens-algs.html#adaboost"><i class="fa fa-check"></i><b>4.3</b> AdaBoost</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-3"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ens-algs.html"><a href="ens-algs.html#gradient-boosting"><i class="fa fa-check"></i><b>4.4</b> Gradient Boosting</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-4"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ml-pe.html"><a href="ml-pe.html"><i class="fa fa-check"></i><b>5</b> Machine Learning Practical Exercise</a></li>
<li class="chapter" data-level="6" data-path="shiny-tut.html"><a href="shiny-tut.html"><i class="fa fa-check"></i><b>6</b> R Shiny Tutorial</a></li>
<li class="chapter" data-level="7" data-path="shiny-pe.html"><a href="shiny-pe.html"><i class="fa fa-check"></i><b>7</b> R Shiny Practical Exercise</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Practical Guide for Machine Learning and R Shiny</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ens-algs" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Ensemble Algorithms</h1>
<div id="bagging" class="section level2">
<h2><span class="header-section-number">4.1</span> Bagging</h2>
<p>Bagging is short for Bootstrapped Aggregation. As you can guess from the name, the Bagging algorithm’s basis is the <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap</a>. With bootstrapping, you can use resampling techniques to estimate an unknown parameter of the data. The bootstrap method computes this estimate by taking random samples, with replacement, of the data and calculating the estimated value a total of <span class="math inline">\(B\)</span> times. The final step is to calculate the average of the estimates over the <span class="math inline">\(B\)</span> bootstrap trials.</p>
<p>With Bagging, the algorithm aggregates predictions from multiple machine learning models. Bagging provides an advantage for models that are high variance by reducing the variance of these models. In essence, Bagging mimics the phenomenon known as the <a href="http://galton.org/search/essays/pages/galton-1907-vox-populi_1.png">“wisdom of the crowd”</a>. In practice the algorithm is relatively simple</p>
<div class="figure" style="text-align: center"><span id="fig:bagging-algorithm"></span>
<img src="img/bagging-algorithm.png" alt="Bagging algorithm from Kuhn and Johnson (2013)." width="90%" />
<p class="caption">
Figure 4.1: Bagging algorithm from Kuhn and Johnson (2013).
</p>
</div>
<p>Since Bagging works well on models with high variance, it is most widely used on CART models. Fundamentally, the Bagging algorithm cast votes on multiple trees that are individually weak learners. However, the aggregated response or classification has an overall reduced error rate without a loss in bias.</p>
<div id="practical-exercise-1" class="section level3 unnumbered">
<h3>Practical Exercise</h3>
<p>For this and the remaining PEs in this chapter, we will use the same solubility and Pima datasets from Chapter <a href="non-lin-algs.html#non-lin-algs">3</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AppliedPredictiveModeling)
<span class="kw">library</span>(rpart)
<span class="kw">library</span>(caret)
<span class="kw">library</span>(partykit)
<span class="kw">library</span>(mlbench)
<span class="kw">library</span>(kernlab)
<span class="kw">library</span>(ipred)
<span class="kw">library</span>(randomForest)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(solubility)
pima_train &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/pima-train.csv&quot;</span>,<span class="dt">header=</span><span class="ot">TRUE</span>)
pima_train &lt;-<span class="st"> </span>pima_train[<span class="kw">complete.cases</span>(pima_train),]</code></pre></div>
<div id="regression-3" class="section level4 unnumbered">
<h4>Regression</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
train_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number=</span><span class="dv">5</span>, <span class="dt">returnResamp=</span><span class="st">&#39;none&#39;</span>)
bag_regress &lt;-<span class="st"> </span><span class="kw">train</span>(solTrainXtrans, solTrainY,
                   <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                   <span class="dt">trControl=</span> train_control
                   )
bag_regress<span class="op">$</span>results</code></pre></div>
<pre><code>##   parameter      RMSE  Rsquared       MAE    RMSESD RsquaredSD      MAESD
## 1      none 0.9208562 0.8011265 0.7022581 0.0404631 0.03403587 0.03130357</code></pre>
</div>
<div id="classification-3" class="section level4 unnumbered">
<h4>Classification</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
bag_class &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="kw">as.factor</span>(diabetes) <span class="op">~</span>., 
                   <span class="dt">data =</span> pima_train,
                   <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                   <span class="dt">trControl=</span> train_control
                   )
bag_class<span class="op">$</span>results</code></pre></div>
<pre><code>##   parameter  Accuracy     Kappa AccuracySD    KappaSD
## 1      none 0.7715822 0.4847493 0.04241899 0.08441819</code></pre>
</div>
</div>
</div>
<div id="random-forest" class="section level2">
<h2><span class="header-section-number">4.2</span> Random Forest</h2>
<p>While Bagging significantly reduced the variance compared to some other machine learning models, it has some drawbacks. In particular, Bagging creates trees on the entire feature space for each sample. Thus, most trees, especially at the top layers will look very similar and as a result most of the trees are not independent from each other. The Random Forest algorithm fixes this problem. Reviewing the algorithm in Figure <a href="ens-algs.html#fig:random-forest-algorithm">4.2</a>, you will notice that instead of building a tree on the entire feature space, Random Forest trees are built using a random sample of <span class="math inline">\(k &lt; P\)</span> of the original predictors. For classification, a general default for the number of predictors at each split point is <span class="math inline">\(k\ =\ \sqrt{P}\)</span>. For regression, the default number of predictors at each split point is <span class="math inline">\(k\ =\ \frac{P}{3}\)</span>. A side benefit of this algorithm is that Random Forest is more computatinally efficient since trees are not built on the entire set of features.</p>
<div class="figure" style="text-align: center"><span id="fig:random-forest-algorithm"></span>
<img src="img/random-forest-algorithm.png" alt="Random Forest algorithm from Kuhn and Johnson (2013)." width="90%" />
<p class="caption">
Figure 4.2: Random Forest algorithm from Kuhn and Johnson (2013).
</p>
</div>
<div id="practical-exercise-2" class="section level3 unnumbered">
<h3>Practical Exercise</h3>
<div id="regresssion" class="section level4 unnumbered">
<h4>Regresssion</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">41</span>)
rf_regress_model &lt;-<span class="st"> </span><span class="kw">randomForest</span>(solTrainXtrans,solTrainY,
                                 <span class="dt">importance=</span><span class="ot">TRUE</span>,
                                 <span class="dt">ntrees=</span><span class="dv">500</span>)
rf_regress_model</code></pre></div>
<pre><code>## 
## Call:
##  randomForest(x = solTrainXtrans, y = solTrainY, importance = TRUE,      ntrees = 500) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 76
## 
##           Mean of squared residuals: 0.4222374
##                     % Var explained: 89.91</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(rf_regress_model<span class="op">$</span>importance)</code></pre></div>
<pre><code>##           %IncMSE IncNodePurity
## FP001 0.006445326      1.786854
## FP002 0.010880283      2.427839
## FP003 0.007691509      2.469004
## FP004 0.025182610     17.044367
## FP005 0.004678159      1.405516
## FP006 0.009439474      4.459932</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#We won&#39;t run this, but this is how you would train this model using CARET</span>
<span class="co"># mtry_min &lt;- floor(ncol(solTrainXtrans)/3)</span>
<span class="co"># mtry_max &lt;- ncol(solTrainXtrans)</span>
<span class="co"># mtry &lt;- seq(mtry_min,mtry_max)</span>
<span class="co"># train_control &lt;- trainControl(method=&#39;cv&#39;, number=5, search=&#39;random&#39;)</span>
<span class="co"># model_metric &lt;- &quot;RMSE&quot;</span>
<span class="co"># tune_grid &lt;- expand.grid(.mtry=mtry)</span>
<span class="co"># </span>
<span class="co"># rf_random_regress &lt;- train(solTrainXtrans, solTrainY,</span>
<span class="co">#                    method = &quot;rf&quot;,</span>
<span class="co">#                    trControl= train_control,</span>
<span class="co">#                    metric = model_metric,</span>
<span class="co">#                    tuneGrid = tune_grid</span>
<span class="co">#                    )</span></code></pre></div>
</div>
<div id="classification-4" class="section level4 unnumbered">
<h4>Classification</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Random search</span>
<span class="kw">set.seed</span>(<span class="dv">41</span>)
mtry_min &lt;-<span class="st"> </span><span class="kw">floor</span>(<span class="kw">sqrt</span>(<span class="kw">ncol</span>(pima_train)<span class="op">-</span><span class="dv">1</span>))
mtry_max &lt;-<span class="st"> </span><span class="kw">ncol</span>(pima_train)<span class="op">-</span><span class="dv">1</span>
mtry &lt;-<span class="st"> </span><span class="kw">seq</span>(mtry_min,mtry_max)
train_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number=</span><span class="dv">5</span>, <span class="dt">search=</span><span class="st">&#39;random&#39;</span>)
model_metric &lt;-<span class="st"> &quot;Accuracy&quot;</span>
tune_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">.mtry=</span>mtry)


rf_random_class &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="kw">as.factor</span>(diabetes) <span class="op">~</span>., 
                   <span class="dt">data =</span> pima_train,
                   <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>,
                   <span class="dt">trControl=</span> train_control,
                   <span class="dt">metric =</span> model_metric,
                   <span class="dt">tuneGrid =</span> tune_grid
                   )
rf_random_class<span class="op">$</span>results</code></pre></div>
<pre><code>##   mtry  Accuracy     Kappa AccuracySD    KappaSD
## 1    2 0.7940864 0.5291364 0.02769544 0.06039786
## 2    3 0.7780581 0.4914831 0.03170987 0.06987462
## 3    4 0.8005909 0.5439405 0.02218887 0.04789905
## 4    5 0.7846155 0.5031842 0.02364283 0.06340367
## 5    6 0.7813880 0.4970204 0.03093920 0.07522984
## 6    7 0.7846667 0.5053203 0.03236422 0.08151918
## 7    8 0.7814921 0.4994510 0.03575589 0.08559938</code></pre>
</div>
</div>
</div>
<div id="adaboost" class="section level2">
<h2><span class="header-section-number">4.3</span> AdaBoost</h2>
<div class="figure" style="text-align: center"><span id="fig:adaboost-algorithm"></span>
<img src="img/adaboost-algorithm.png" alt="Adaboost classification algorithm from Kuhn and Johnson (2013)." width="90%" />
<p class="caption">
Figure 4.3: Adaboost classification algorithm from Kuhn and Johnson (2013).
</p>
</div>
<div id="practical-exercise-3" class="section level3 unnumbered">
<h3>Practical Exercise</h3>
</div>
</div>
<div id="gradient-boosting" class="section level2">
<h2><span class="header-section-number">4.4</span> Gradient Boosting</h2>
<div class="figure" style="text-align: center"><span id="fig:gradient-boosting-regression"></span>
<img src="img/gradient-boosting-regression.png" alt="Gradient Boosting regression algorithm from Kuhn and Johnson (2013)." width="90%" />
<p class="caption">
Figure 4.4: Gradient Boosting regression algorithm from Kuhn and Johnson (2013).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:gradient-boosting-classification"></span>
<img src="img/gradient-boosting-classification.png" alt="Gradient Boosting classification algorithm from Kuhn and Johnson (2013)." width="90%" />
<p class="caption">
Figure 4.5: Gradient Boosting classification algorithm from Kuhn and Johnson (2013).
</p>
</div>
<div id="practical-exercise-4" class="section level3 unnumbered">
<h3>Practical Exercise</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="non-lin-algs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ml-pe.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
