[
["index.html", "A Practical Guide for Machine Learning and R Shiny Preface Structure of the book", " A Practical Guide for Machine Learning and R Shiny Cardy Moten III 2018-02-05 Preface For the next two days, we will focus on the “how” of machine learning. This does not mean we are simply glossing over the “why” of machine learning, but quite frankly, we will not have the time in this short course. After we cover machine learning we will spend two days learning about R Shiny and will build a couple of web applications with it. Having said all that, a good textbook reference to start learning the about the “why” of machine learning mathematics is the book The Elements of Statistical Learning by Hastie, Tibshirani, and Friedman (2009). For a more hands-on approach, read Neural Networks and Deep Learning by Nielsen (2015). Structure of the book Chapter 1 provides a general overveiw of machine learning. Chapters 2 - 5 covers machine learning algorithms and a practical exercise. Chapters 6 and 7 focus on R shiny and a practical exercise. References "],
["ml-overview.html", "Chapter 1 Machine Learning Overview 1.1 What is Machine Learning? 1.2 What machine learning is not 1.3 What do I need to know to get started with machine learning?", " Chapter 1 Machine Learning Overview 1.1 What is Machine Learning? In simple terms, machine learning is a statistical modeling technique that focuses on algorithmic-driven models instead of data-driven models. Figure 1.1 shows a comparison of these two approaches and is an adaptation of a figure in this article by Breiman (2001). Figure 1.1: A statistical model comparison. The model at the top illustrates the original problem to be solved; which is how to best represent the relationship between a vector in input variables \\(x\\) and a corresponding response variable \\(y\\)? The data-modeling approach in the lower left assumes that a stochastic data model represents this relationship (Breiman 2001). The analyst using this method will then estimate the parameters of the model and validate the model using goodness of fit tests. Thus, a general function representing this approach would be \\[\\text{response variables} = f(\\text{predictor variables, random noise, parameters})\\] In comparison to the data-modeling approach, the analytic-modeling approach doesn’t make any assumptions about the relationship between \\(x\\) and \\(y\\). Instead, the focus is on finding a function \\(f(x)\\) that will input a variable \\(x\\) to predict a value for \\(y\\) and is the model in the lower right of Figure 1.1. 1.2 What machine learning is not While machine learning has made significant breakthroughs in many areas (web search, image recognition, game AI, medical diagnosis, prediction, and classification to name a few), it is a technique that is not without limitations.For this course, we will cover a few of these limitations, but you can read a more in-depth critical analysis presented by Marcus (2018). Machine learning models require a lot of data For machine learning algorithms to learn well, they need lots of data. A review of the types of use cases that these models have achieved a lot of success will give you an appreciation for the amount of data needed to train, validate, and use these models into a production environment. Machine learning models are not a substitute for domain expertise When appropriately used, machine learning models can help us to find hidden patterns in our data that are not possible on our own. While this is a great benefit, it does not alleviate the burden of understanding what these results mean, and whether they even matter when it comes to finding an adequate solution to a business problem. Machine learning models require constant maintenance This statement should not come as a surprise since machine learning models are an extension of statistics in some ways. In general machine learning problems work best with applications that are similar to their training context. Even then, mistakes can happen, and the modeler must make adjustments. 1.3 What do I need to know to get started with machine learning? Once you are familiar with the concepts in machine learning, you will realize that most of the ideas are similar to other statistical methods. The key here is learning the following thoughts. The role of data in machine learning Machine learning algorithms primarily use tabular data. Nevertheless, machine learning literature has its origin in computer science, and some of the terms used to describe data are slightly different than traditional statistics. Primarily, the regressor variables in machine learning are called features. Features are used to make predictions on target or outcome measures. The difference between parametric and nonparametric machine learning algorithms Parametric Models Parametric machine learning models are based on modeling assumptions about the mapping of the feature variables to the target variable. Some examples of parametric machine learning models are Linear Regression, Logistic Regression, and Linear Discriminant Analysis. In general parametric models are simpler, faster to compute, and require fewer data. A key drawback, however, is that parametric models are rigid and do not adjust well to variations in the data (Brownlee 2017). Nonparametric Models Nonparametric machine learning models are not based on any modeling assumptions about the mapping of the feature variables to the target variable. Some examples of nonparametric models are \\(k\\)-Nearest Neighbors, Na{}ve Bayes, Support Vector Machines, Neural Networks, and Decision Trees. In general nonparametric models more complex, slower to compute, and require more data than parametric models. A principal drawback of nonparametric models, however, is their inconsistent results (Brownlee 2017). The difference between supervised, unsupervised and semi-supervised learning The key takeaway here is that supervised learning models predict a value; unsupervised learning models describe associations and patterns in a dataset, and semi-supervised learning models are combinations of the two (Hastie, Tibshirani, and Friedman 2009).Furthermore, supervised learning involves data that has labeled features and target variables. In contrast, unsupervised learning uses data that does not have any feature or target variable labels. The bias-variance tradeoff The company EliteDataScience created an infographic that provides a vivid explanation of the importance of the bias-variance tradeoff. The key to this concept is to understand that bias is the degree to which the predictions or classifications are different from the actual value. Parametric models tend to have higher bias than nonparametric models. Conversely, variance refers to how sensitive the model is to noise in the data. For variance error, nonparametric models will tend to be more sensitive to different sets of training data than parametric models. Another critical aspect is that bias and variance have an inverse relationship. In other words, models that usually have a high bias also have low variance. By contrast, models that have low bias will usually exhibit high variance. Hence, it is essential that you tune your modeling parameters and try as many different models as possible to evaluate model performance. Overfitting and underfitting and what to do about it For underfitted models, the answer is simple; don’t use the model. Overfitting, however, is a different problem. In this case, the model fits the data too well to apply for any general setting. Thus, you will have to spend some time making adjustments to the model and determining how best to engineer the features to reduce the risk of overfitting. References "],
["lin-algs.html", "Chapter 2 Linear Algorithms 2.1 Gradient Descent 2.2 Practical Exercises 2.3 Linear Discriminant Analysis", " Chapter 2 Linear Algorithms 2.1 Gradient Descent One of the most common concepts for all machine learning algorithms is optimization. Of the many optimization methods, the most widely used optimization method in machine learning is gradient descent. This extensive use of gradient descent is because gradient descent is straightforward to learn and compatible with any machine learning algorithm. For this section, we will use gradient descent with linear and logistic regression. Linear Regression Model Before discussing the gradient descent algorithm, let’s review the linear regression. Recall the general linear regression equation is: \\[y = h(x) = \\sum_{i=1}^{N}w_ix_i + b + \\epsilon\\] where \\(y\\) is the target variable, \\(x\\) is the feature variables, \\(w_i\\) are the weights of the \\(i\\)th feature variable, \\(b\\) is the bias, and \\(\\epsilon\\) is the irreducible error. We use machine learning algorithms to estimate the bias and the weights of the feature variables. Cost Function Simple Linear Regression In order to optimize the weight and the bias variable, we need to optimize the cost (loss) function. For linear regression this function, \\(J(w,b)\\) is the Mean Squared Error (MSE) and we can calculate it by: \\[MSE = J(w,b) = \\frac{1}{m}\\sum_{i = 1}^{m}\\left(y_i - \\left(wx_i+b\\right)\\right)^2\\] Since we are adjusting the cost function by the weight and the bias parameters, we must take the partial derivative with respect to each of these to calculate the gradient. \\[ J&#39;(w,b) = \\begin{bmatrix} \\frac{\\partial J}{\\partial w}\\\\ \\frac{\\partial J}{\\partial b} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{m}\\sum-2*x_i(y_i - (wx_i + b)) = \\delta_w\\\\ \\frac{1}{m}\\sum-2*(y_i - (wx_i + b)) = \\delta_b \\end{bmatrix} \\] Multiple Linear Regression For multiple linear regression, we introduce a parameter matrix \\(\\theta\\) that contains the bias and weight parameters where: \\[ \\begin{align} h_\\theta(x) &amp;= \\theta_0 + \\theta_1x_1 + \\dots + \\theta_nx_n\\\\ h(x) &amp;= \\sum_{i=0}^{n} \\theta_ix_i = \\theta^Tx \\end{align} \\] The cost function is: \\[ J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m} \\left(h_\\theta(x^{(i)})-y^{(i)}\\right)^2 \\] In matrix form, the cost function becomes \\[ J(\\theta) = \\frac{1}{2m}(X\\theta - y)^T(X\\theta-y) \\] where \\(X\\) is a \\(m \\times n\\) design matrix, \\(\\theta\\) is a \\(n \\times 1\\) parameter matrix and \\(y\\) is a \\(m \\times 1\\) vector of observed targets. Taking the derivative with respect to \\(\\theta\\) yields: \\[ J&#39;(\\theta) = \\frac{1}{m}X^T(X\\theta - y) \\] See the video below for an example derivation of the derivative of the cost matrix: Logistic Regression Another application of the gradient descent algorithm is for logistic regression. Recall that we use logistic regression when the target variable is categorical, and there are only two possible classifications. We show the general equation as \\[ h_\\theta(x) = g(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}} \\] and \\[ g(z) = \\frac{1}{1 + e^{-z}} \\] The above equation is called a sigmoid or logistic function. Essentially, we first perform a linear regression on the weights and bias and then feed that predicted value into the sigmoid function to map a real value between 0 and 1. sigmoid &lt;- function(z){ res &lt;- 1 / (1 + exp(-z)) res } Figure 2.1: Example Sigmoid function plot. The cost function for logistic regression will differ now, that the function we are analyzing is non-linear. First let’s assume the following: \\[ \\begin{align} P(y=1|x;\\theta) &amp;= h_\\theta(x)\\\\ P(y=0|x;\\theta) &amp;= 1-h_\\theta(x)\\\\ P(y|x;\\theta) &amp;= \\left(h_\\theta(x)\\right)^y\\left(1-h_\\theta(x)\\right)^{1-y} \\end{align} \\] We now can find the log cross-entropy cost by: \\[ J(\\theta) = -\\frac{1}{m}\\sum_{i=0}^m\\left[y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})\\right] \\] where \\(h_\\theta(x)\\) is the sigmoid function. When taking the derivative with respect to \\(\\theta\\), recall that \\(g&#39;(z) = g(z)(1-g(z))\\). Thus, \\[ \\begin{align} J&#39;(\\theta) &amp;= \\frac{\\partial}{\\partial\\theta_j}-\\frac{1}{m}\\sum_{i=0}^m\\left[y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})\\right]\\\\ &amp;= -\\frac{1}{m}\\left(y\\frac{1}{g(\\theta^Tx)}-(1-y)\\frac{1}{1-g(\\theta^Tx)}\\right)\\frac{\\partial}{\\partial\\theta_j}g(\\theta^Tx)\\\\ &amp;=-\\frac{1}{m}\\left(y\\frac{1}{g(\\theta^Tx)}-(1-y)\\frac{1}{1-g(\\theta^Tx)}\\right)g(\\theta^Tx)(1-g(\\theta^Tx))\\frac{\\partial}{\\partial\\theta_j}\\theta^Tx\\\\ &amp;=-\\frac{1}{m}\\left(y(1-g(\\theta^Tx)-(1-y)g(\\theta^Tx)\\right)x_j\\\\ &amp;=-\\frac{1}{m}\\left(y(1-g(\\theta^Tx)-(1-y)g(\\theta^Tx)\\right)x_j\\\\ &amp;= -\\frac{1}{m}\\left(y-g(\\theta^Tx)\\right)x_j\\\\ &amp;=\\frac{1}{m}\\left(g(\\theta^Tx)-y\\right)x_j\\\\ &amp;=\\frac{1}{m}\\left(h_\\theta(x)-y\\right)x_j\\\\ \\end{align} \\] What is interesting to note is that this gradient function looks precisely like the gradient function for linear regression. The difference, however, is that the function \\(h_\\theta(x)\\) is a sigmoid function and not a linear function of the weights and bias parameters. For further details of the above derivations see Ng (2000) and Fortuner (2017). Gradient Descent Algorithm Finally, to solve for the optimal weight and bias, we will add a learning parameter, \\(\\alpha\\), to adjust the steps of the gradient. Simple Linear Regression The algorithm we will use is: \\[ \\text{Repat until convergence } \\{\\\\ w := w - \\alpha\\delta_w\\\\ b := b - \\alpha\\delta_b\\\\ \\} \\] Multiple Linear Regression For multiple linear regression the algorithm changes to: \\[ \\text{Repat until convergence } \\{\\\\ \\theta_j := \\theta_j - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}\\left(h_\\theta(x^{(i)}-y^{(i)}\\right)x_{j}^{(i)}\\\\ \\} \\] In this algorithm we are simultaneously updating the weights, \\(\\theta_j\\), for all \\(j\\in{(0,\\dots,n)}\\). Recall that \\(\\theta_0\\) is the bias term and \\(x_0^{1}=1\\). In matrix form, our algorithm will look like this: \\[ \\text{Repat until convergence } \\{\\\\ \\delta = \\frac{1}{m}X^T(X\\theta - y)\\\\ \\theta:=\\theta-\\alpha\\delta\\\\ \\} \\] Logistic Regression The matrix form of the stochastic gradient descent algorithm has the form: \\[ \\text{Repat until convergence } \\{\\\\ \\delta = \\frac{1}{m}X^T(sigmoid(X\\theta) - y)\\\\ \\theta:=\\theta-\\alpha\\delta\\\\ \\} \\] Gradient Descent Intuition Figure 2.2 demonstrates the basic intuition behind the gradient algorithm. Fundamentally, if we pick a point along the graph of the cost function, and the gradient is negative, the algorithm will update by moving the more to the right. Conversely, if the gradient is positive, the algorithm will move the cost value more to the left. Figure 2.2: A simple example of gradient descent. Figure 2.3 is a multi-dimensional view of the cost function, and the underlying concept is still the same. Figure 2.3: A surface plot of a quadratic cost function. Figure 2.4 is a plot of the log-entropy function for logistic regression. Figure 2.4: A simple example of gradient descent. While the ideal cost function to minimize would be a convex function, this is not always practical and there are ways to deal with that as discussed in the following video. 2.2 Practical Exercises This practical exercieses are based on code provided by Fortuner (2017) and Brownlee (2017). 2.2.1 Simple Linear Regression Data Suppose we have the following dataset in which we have a unique Company ID, radio advertising expenses in dollars, and annual sales as a result of those expenses in dollars. data &lt;- read.csv(&quot;data/Advertising-Radio.csv&quot;,header=TRUE) head(data) ## company radio sales ## 1 1 37.8 22.1 ## 2 2 39.3 10.4 ## 3 3 45.9 9.3 ## 4 4 41.3 18.5 ## 5 5 10.8 12.9 ## 6 6 48.9 7.2 A view of the data shows that there appears to be a positive correlation between radio advertising spending and sales. plot(data$radio,data$sales,xlab= &quot;Radio&quot;, ylab = &quot;Sales&quot;, col=&quot;dodgerblue&quot;,pch=20) Making Predictions For this model, we want to predict sales based on the amount spent for radio advertising. Thus our formula will be \\[\\text{Sales} = \\text{Weight} \\times \\text{Radio} + \\text{Bias}\\] The gradient descent algorithm will attempt to learn the optimal values for the Weight and Bias. Simple Regression Function simple_regress &lt;- function(features,weight,bias){ return(weight*features + bias) } Cost function Code cost_function &lt;- function(features,targets,weight,bias){ num_items &lt;- length(targets) total_error &lt;- 0 for(i in seq_along(1:num_items)){ total_error &lt;- total_error + (targets[i] - (weight * features[i] + bias))^2 } return(total_error/num_items) } Gradient Descent Code update_weight &lt;- function(features,targets,weight,bias,learning_rate){ delta_weight &lt;- 0 delta_bias &lt;- 0 num_items &lt;- length(targets) for(i in seq_along(1:num_items)){ #Calculate gradients error &lt;- (targets[i] - (weight * features[i] + bias)) delta_weight &lt;- delta_weight + -2 * features[i] * error delta_bias &lt;- delta_bias + -2 * error } weight &lt;- weight - learning_rate * (delta_weight/num_items) bias &lt;- bias - learning_rate * (delta_bias/num_items) res &lt;- c(weight,bias) res } Training the model We are now ready to train the final model. To do this we will iterate over a set number of trials and update the weight and bias parameters at each iteration. We will also track the cost history. train &lt;- function(features,targets,weight,bias,learning_rate,iters){ cost_history &lt;- numeric(iters) coef_history &lt;- list() for(i in seq_along(1:iters)){ tmp_coef &lt;- update_weight(features,targets,weight,bias,learning_rate) weight &lt;- tmp_coef[1] bias &lt;- tmp_coef[2] coef_history[[i]] &lt;- c(bias,weight) cost &lt;- cost_function(features,targets,weight = weight, bias = bias) cost_history[i] &lt;- cost if(i == 1 | i %% 10 == 0){ cat(&quot;iter: &quot;, i, &quot;weight: &quot;, weight, &quot;bias: &quot;, bias, &quot;cost: &quot;, cost, &quot;\\n&quot;) } } res &lt;- list(Weight = weight, Bias = bias, Cost = cost_history,Coefs = coef_history) res } fit &lt;- train(features = data$radio,targets = data$sales,weight = 0.03, bias = 0.0014, learning_rate = 0.001,iters = 30) ## iter: 1 weight: 0.7255664 bias: 0.02804636 cost: 86.42445 ## iter: 10 weight: 0.484637 bias: 0.06879067 cost: 42.72917 ## iter: 20 weight: 0.4837035 bias: 0.1219333 cost: 42.44643 ## iter: 30 weight: 0.4820883 bias: 0.1747496 cost: 42.1673 The plot below shows how the train() funtion iterated through the coefficient history. plot(data$radio,data$sales,xlab= &quot;Radio&quot;, ylab = &quot;Sales&quot;, col=&quot;dodgerblue&quot;,pch=20,main=&quot;Final Plot With Coefficient History&quot;) for(i in 1:30){ abline(coef=fit$Coefs[[i]], col = rgb(0.8,0,0,0.3)) } abline(coef = c(fit$Bias,fit$Weight),col=&quot;red&quot;) This is a plot of the cost history. plot(fit$Cost,type=&quot;l&quot;,col=&quot;blue&quot;, xlab = &quot;Iteration&quot;,ylab=&quot;Cost&quot;,main = &quot;Error Rate Per Iteration&quot;) Exercises Run the command res &lt;- lm(data$sales ~ data$radio) and note the values for the weight and bias. Plot the fitted line from res with the data and comapre that line to the trained model. Adjust the fit object to obtain an estimate close to the noted parameters. 2.2.2 Multiple Linear Regression For this exercise, we will predict total sales based on TV, Radio, and Newspaper advertising costs. Data multi_data &lt;- read.csv(&quot;data/Advertising.csv&quot;, header = TRUE) head(multi_data) ## company TV radio newspaper sales ## 1 1 230.1 37.8 69.2 22.1 ## 2 2 44.5 39.3 45.1 10.4 ## 3 3 17.2 45.9 69.3 9.3 ## 4 4 151.5 41.3 58.5 18.5 ## 5 5 180.8 10.8 58.4 12.9 ## 6 6 8.7 48.9 75.0 7.2 Since we are now dealing with multiple variables, we will need to view a pairs plot # Code for panel.cor found at https://www.r-bloggers.com/scatter-plot-matrices-in-r/ panel.cor &lt;- function(x, y, digits = 2, cex.cor, ...) { usr &lt;- par(&quot;usr&quot;); on.exit(par(usr)) par(usr = c(0, 1, 0, 1)) # correlation coefficient r &lt;- cor(x, y) txt &lt;- format(c(r, 0.123456789), digits = digits)[1] txt &lt;- paste(&quot;r= &quot;, txt, sep = &quot;&quot;) text(0.5, 0.6, txt) # p-value calculation p &lt;- cor.test(x, y)$p.value txt2 &lt;- format(c(p, 0.123456789), digits = digits)[1] txt2 &lt;- paste(&quot;p= &quot;, txt2, sep = &quot;&quot;) if(p&lt;0.01) txt2 &lt;- paste(&quot;p= &quot;, &quot;&lt;0.01&quot;, sep = &quot;&quot;) text(0.5, 0.4, txt2) } pairs(multi_data[,2:5],lower.panel = panel.smooth, upper.panel = panel.cor) 2.2.2.1 Cost Function Code multi_cost &lt;- function(features,target,theta){ sum((features %*% theta - target)^2) / (2*length(target)) } Training Function Code multi_train &lt;- function(features,target,theta,learn_rate,iters){ cost_history &lt;- double(iters) for(i in seq_along(cost_history)){ error &lt;- (features %*% theta - target) delta &lt;- t(features) %*% error / length(target) theta &lt;- theta - learn_rate * delta cost_history[i] &lt;- multi_cost(features,target,theta) } res &lt;- list(Coefs = theta, Costs = cost_history) res } Results To make computing the gradient easier, we will normalize the feature data such that \\(x \\in \\{-1,1\\}\\). normalize_data &lt;- function(data){ cols &lt;- ncol(data) for(i in 1:cols){ tmp_mean &lt;- mean(data[,i]) tmp_range &lt;- range(data[,i])[2] - range(data[,i])[1] res &lt;- (data[,i] - tmp_mean) / tmp_range data[,i] &lt;- res } data } multi_features &lt;- multi_data[,2:4] multi_features &lt;- normalize_data(multi_features) multi_target &lt;- multi_data[,5] features_matrix &lt;- cbind(1,as.matrix(multi_features)) theta &lt;- matrix(0,nrow=ncol(features_matrix)) rownames(theta) &lt;- c(&quot;Intercept&quot;,names(multi_features)) num_iters &lt;- 1000 learn_rate &lt;- 0.0005 multi_fit &lt;- multi_train(features_matrix,multi_target,theta,learn_rate,num_iters) multi_fit$Coefs ## [,1] ## Intercept 5.5184872 ## TV 0.5767349 ## radio 0.4366550 ## newspaper 0.1098191 plot(multi_fit$Costs,type=&quot;l&quot;,col=&quot;blue&quot;,xlab=&quot;Iteration&quot;,ylab=&quot;Cost&quot;,main=&quot;Error Rate Per Iteration&quot;) test_fit &lt;- lm(sales ~ TV + radio + newspaper, data = multi_data) Exercises Tune the iterations and the learning rate and attempt to reduce the model cost. Run the command test_fit &lt;- lm(sales ~ TV + radio + sales, data = multi_data) Compute the cost of test_fit (Hint: use names(test_fit) to find out how to extract the coefficients of the model ) 2.2.3 Logistic Regression During this exercise, we will classify whether studens will pass (1) or fail (0) a test based on the amount of hours spent studying and hours slept. Data log_data &lt;- read.csv(&quot;data/data_classification.csv&quot;,header=TRUE) head(log_data) ## studied slept passed ## 1 4.855064 9.63996157 1 ## 2 8.625440 0.05892653 0 ## 3 3.828192 0.72319923 0 ## 4 7.150955 3.89942042 1 ## 5 6.477900 8.19818055 1 ## 6 1.922270 1.33142727 0 The plot below shows the current data color_vec &lt;- ifelse(log_data$passed==1,&quot;orange&quot;,&quot;blue&quot;) plot(log_data$slept,log_data$studied,col=color_vec,xlab=&quot;Hours Slept&quot;,ylab=&quot;Hours Studied&quot;) legend(&quot;topright&quot;,c(&quot;Pass&quot;,&quot;Fail&quot;),col=c(&quot;orange&quot;,&quot;blue&quot;),pch=c(1,1)) Generate a vector of predictions log_predict &lt;- function(features, theta){ z &lt;- features %*% theta res &lt;- sigmoid(z) res } Cost function code log_cost &lt;- function(features, theta, targets){ m &lt;- length(targets) g &lt;- log_predict(features,theta) res &lt;- (1/m) * sum((-targets * log(g)) - ((1-targets) * log(1-g))) res } Training model code log_train &lt;- function(features,theta,targets,learn_rate, iters){ cost_history &lt;- double(iters) for(i in seq_along(cost_history)){ preds &lt;- log_predict(features,theta) error &lt;- (preds - targets) delta &lt;- t(features) %*% error / length(targets) theta &lt;- theta - learn_rate * delta cost &lt;- log_cost(features,theta,targets) cost_history[i] &lt;- cost if(i == 1 | i %% 1000 == 0){ cat(&quot;iter: &quot;, i, &quot;cost: &quot;, cost, &quot;\\n&quot;) } } res &lt;- list(Coefs = theta, Costs = cost_history) res } Decision boundary code boundary &lt;- function(prob){ res &lt;- ifelse(prob&gt;=.5,1,0) res } Classification accuracy code log_accuracy &lt;- function(preds,targets){ diff &lt;- preds - targets res &lt;- 1 - sum(diff)/length(diff) } Results log_features &lt;- log_data[,1:2] log_targets &lt;- log_data[,3] log_design &lt;- cbind(1,as.matrix(log_features)) log_theta &lt;- matrix(0,nrow=ncol(log_design)) rownames(log_theta) &lt;- c(&quot;Intercept&quot;,names(log_features)) learn_rate &lt;- 0.02 num_iters &lt;- 3000 log_fit &lt;- log_train(log_design,log_theta,log_targets,learn_rate,num_iters) ## iter: 1 cost: 0.6582674 ## iter: 1000 cost: 0.4469503 ## iter: 2000 cost: 0.3773433 ## iter: 3000 cost: 0.3408168 log_fit$Coefs ## [,1] ## Intercept -3.8281563 ## studied 0.4802045 ## slept 0.3435157 plot(log_fit$Costs,type=&quot;l&quot;,col=&quot;blue&quot;) predictions &lt;- log_predict(log_design,log_fit$Coefs) classifications &lt;- boundary(predictions) fit_accuracy &lt;- log_accuracy(classifications,log_targets) fit_accuracy ## [1] 0.91 plot(predictions,col=color_vec) abline(h=0.5,lty=2) title(&quot;Actual Classification vs Predicted Probability&quot;) legend(&quot;topright&quot;,c(&quot;Pass&quot;,&quot;Fail&quot;),col=c(&quot;orange&quot;,&quot;blue&quot;),pch=c(1,1),horiz = TRUE) Exercises Tune the iterations and the learning rate and attempt to improve the model accuracy. Run the command test_log &lt;- glm(passed~slept+studied,family = 'binomial',data=log_data) Compare the cost and accuracy of test_log with log_fit. 2.3 Linear Discriminant Analysis References "],
["non-lin-algs.html", "Chapter 3 Non-linear Algorithms", " Chapter 3 Non-linear Algorithms Now I’ll teach you some crazy math, but I need to work it out first… "],
["ens-algs.html", "Chapter 4 Ensemble Algorithms", " Chapter 4 Ensemble Algorithms "],
["ml-pe.html", "Chapter 5 Machine Learning Practical Exercise", " Chapter 5 Machine Learning Practical Exercise "],
["shiny-tut.html", "Chapter 6 R Shiny Tutorial", " Chapter 6 R Shiny Tutorial "],
["shiny-pe.html", "Chapter 7 R Shiny Practical Exercise", " Chapter 7 R Shiny Practical Exercise "],
["references.html", "References", " References "]
]
