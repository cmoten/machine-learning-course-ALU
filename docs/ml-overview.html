<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Practical Guide for Machine Learning and R Shiny</title>
  <meta name="description" content="Everything you need (and nothing more) to start a bookdown book.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="A Practical Guide for Machine Learning and R Shiny" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="<a href="https://cmoten.github.io/machine-learning-course-ALU" class="uri">https://cmoten.github.io/machine-learning-course-ALU</a>" />
  
  <meta property="og:description" content="Everything you need (and nothing more) to start a bookdown book." />
  <meta name="github-repo" content="cmoten/machine-learning-course-ALU" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Practical Guide for Machine Learning and R Shiny" />
  
  <meta name="twitter:description" content="Everything you need (and nothing more) to start a bookdown book." />
  

<meta name="author" content="Cardy Moten III">


<meta name="date" content="2018-02-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="lin-algs.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning & R Shiny</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ml-overview.html"><a href="ml-overview.html"><i class="fa fa-check"></i><b>1</b> Machine Learning Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="ml-overview.html"><a href="ml-overview.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="ml-overview.html"><a href="ml-overview.html#what-machine-learning-is-not"><i class="fa fa-check"></i><b>1.2</b> What machine learning is not</a><ul>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-require-a-lot-of-data"><i class="fa fa-check"></i>Machine learning models require a lot of data</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-are-not-a-substitute-for-domain-expertise"><i class="fa fa-check"></i>Machine learning models are not a substitute for domain expertise</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-models-require-constant-maintenance"><i class="fa fa-check"></i>Machine learning models require constant maintenance</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ml-overview.html"><a href="ml-overview.html#what-do-i-need-to-know-to-get-started-with-machine-learning"><i class="fa fa-check"></i><b>1.3</b> What do I need to know to get started with machine learning?</a><ul>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-role-of-data-in-machine-learning"><i class="fa fa-check"></i>The role of data in machine learning</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-difference-between-parametric-and-nonparametric-machine-learning-algorithms"><i class="fa fa-check"></i>The difference between parametric and nonparametric machine learning algorithms</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-difference-between-supervised-unsupervised-and-semi-supervised-learning"><i class="fa fa-check"></i>The difference between supervised, unsupervised and semi-supervised learning</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#the-bias-variance-tradeoff"><i class="fa fa-check"></i>The bias-variance tradeoff</a></li>
<li class="chapter" data-level="" data-path="ml-overview.html"><a href="ml-overview.html#overfitting-and-underfitting-and-what-to-do-about-it"><i class="fa fa-check"></i>Overfitting and underfitting and what to do about it</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lin-algs.html"><a href="lin-algs.html"><i class="fa fa-check"></i><b>2</b> Linear Algorithms</a><ul>
<li class="chapter" data-level="2.1" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent"><i class="fa fa-check"></i><b>2.1</b> Gradient Descent</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#linear-regression-model"><i class="fa fa-check"></i>Linear Regression Model</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#cost-function"><i class="fa fa-check"></i>Cost Function</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#logistic-regression"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent-algorithm"><i class="fa fa-check"></i>Gradient Descent Algorithm</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#gradient-descent-intuition"><i class="fa fa-check"></i>Gradient Descent Intuition</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="lin-algs.html"><a href="lin-algs.html#practical-exercises"><i class="fa fa-check"></i><b>2.2</b> Practical Exercises</a><ul>
<li class="chapter" data-level="2.2.1" data-path="lin-algs.html"><a href="lin-algs.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>2.2.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="lin-algs.html"><a href="lin-algs.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>2.2.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="2.2.3" data-path="lin-algs.html"><a href="lin-algs.html#logistic-regression-1"><i class="fa fa-check"></i><b>2.2.3</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lin-algs.html"><a href="lin-algs.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>2.3</b> Linear Discriminant Analysis</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-intuition"><i class="fa fa-check"></i>LDA Intuition</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-estimates-for-one-predictor"><i class="fa fa-check"></i>LDA Estimates for One Predictor</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-with-miltiple-predictors"><i class="fa fa-check"></i>LDA With Miltiple Predictors</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="lin-algs.html"><a href="lin-algs.html#practical-exercise"><i class="fa fa-check"></i><b>2.4</b> Practical Exercise</a><ul>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#data-2"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="lin-algs.html"><a href="lin-algs.html#lda-scoring"><i class="fa fa-check"></i>LDA Scoring</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="non-lin-algs.html"><a href="non-lin-algs.html"><i class="fa fa-check"></i><b>3</b> Non-linear Algorithms</a><ul>
<li class="chapter" data-level="3.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>3.1</b> Classification and Regression Trees (CART)</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#what-are-cart-models"><i class="fa fa-check"></i>What are CART models?</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#how-does-a-cart-model-learn-from-data"><i class="fa fa-check"></i>How does a CART model learn from data?</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#pre-processing-requirements"><i class="fa fa-check"></i>Pre-processing requirements?</a></li>
<li class="chapter" data-level="3.1.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise"><i class="fa fa-check"></i><b>3.1.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="non-lin-algs.html"><a href="non-lin-algs.html#naive-bayes"><i class="fa fa-check"></i><b>3.2</b> Naive Bayes</a><ul>
<li class="chapter" data-level="3.2.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-1"><i class="fa fa-check"></i><b>3.2.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="non-lin-algs.html"><a href="non-lin-algs.html#k-nearest-neigbors"><i class="fa fa-check"></i><b>3.3</b> k-Nearest Neigbors</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#curse-of-dimensionality"><i class="fa fa-check"></i>Curse of Dimensionality</a></li>
<li class="chapter" data-level="3.3.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-2"><i class="fa fa-check"></i><b>3.3.1</b> Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="non-lin-algs.html"><a href="non-lin-algs.html#support-vector-machines"><i class="fa fa-check"></i><b>3.4</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#regression-1"><i class="fa fa-check"></i>Regression</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#classification-1"><i class="fa fa-check"></i>Classification</a></li>
<li class="chapter" data-level="" data-path="non-lin-algs.html"><a href="non-lin-algs.html#optimizaton-forumulation"><i class="fa fa-check"></i>Optimizaton Forumulation</a></li>
<li class="chapter" data-level="3.4.1" data-path="non-lin-algs.html"><a href="non-lin-algs.html#practical-exerecise-3"><i class="fa fa-check"></i><b>3.4.1</b> Practical Exerecise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ens-algs.html"><a href="ens-algs.html"><i class="fa fa-check"></i><b>4</b> Ensemble Algorithms</a><ul>
<li class="chapter" data-level="4.1" data-path="ens-algs.html"><a href="ens-algs.html#bagging"><i class="fa fa-check"></i><b>4.1</b> Bagging</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-1"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ens-algs.html"><a href="ens-algs.html#random-forest"><i class="fa fa-check"></i><b>4.2</b> Random Forest</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-2"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ens-algs.html"><a href="ens-algs.html#adaboost"><i class="fa fa-check"></i><b>4.3</b> AdaBoost</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-3"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ens-algs.html"><a href="ens-algs.html#gradient-boosting"><i class="fa fa-check"></i><b>4.4</b> Gradient Boosting</a><ul>
<li class="chapter" data-level="" data-path="ens-algs.html"><a href="ens-algs.html#practical-exercise-4"><i class="fa fa-check"></i>Practical Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ml-pe.html"><a href="ml-pe.html"><i class="fa fa-check"></i><b>5</b> Machine Learning Practical Exercise</a><ul>
<li class="chapter" data-level="5.1" data-path="ml-pe.html"><a href="ml-pe.html#modeling-workflow"><i class="fa fa-check"></i><b>5.1</b> Modeling Workflow</a></li>
<li class="chapter" data-level="5.2" data-path="ml-pe.html"><a href="ml-pe.html#performance-metrics"><i class="fa fa-check"></i><b>5.2</b> Performance Metrics</a></li>
<li class="chapter" data-level="5.3" data-path="ml-pe.html"><a href="ml-pe.html#practice-projects"><i class="fa fa-check"></i><b>5.3</b> Practice Projects</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="shiny-tut.html"><a href="shiny-tut.html"><i class="fa fa-check"></i><b>6</b> R Shiny Tutorial</a><ul>
<li class="chapter" data-level="" data-path="shiny-tut.html"><a href="shiny-tut.html#practical-exerecise-4"><i class="fa fa-check"></i>Practical Exerecise</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Practical Guide for Machine Learning and R Shiny</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ml-overview" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Machine Learning Overview</h1>
<div id="what-is-machine-learning" class="section level2">
<h2><span class="header-section-number">1.1</span> What is Machine Learning?</h2>
<p>In simple terms, machine learning is a statistical modeling technique that focuses on algorithmic-driven models instead of data-driven models. Figure <a href="ml-overview.html#fig:model-compare">1.1</a> shows a comparison of these two approaches and is an adaptation of a figure in this <a href="https://projecteuclid.org/euclid.ss/1009213726">article</a> by <span class="citation">Breiman (<a href="#ref-breiman2001statistical">2001</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:model-compare"></span>
<img src="img/learning-models.png" alt="A statistical model comparison." width="90%" />
<p class="caption">
Figure 1.1: A statistical model comparison.
</p>
</div>
<p>The model at the top illustrates the original problem to be solved; which is how to best represent the relationship between a vector in input variables <span class="math inline">\(x\)</span> and a corresponding response variable <span class="math inline">\(y\)</span>? The data-modeling approach in the lower left assumes that a stochastic data model represents this relationship <span class="citation">(Breiman <a href="#ref-breiman2001statistical">2001</a>)</span>. The analyst using this method will then estimate the parameters of the model and validate the model using goodness of fit tests. Thus, a general function representing this approach would be</p>
<p><span class="math display">\[\text{response variables} = f(\text{predictor variables, random noise, parameters})\]</span></p>
<p>In comparison to the data-modeling approach, the analytic-modeling approach doesn’t make any assumptions about the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. Instead, the focus is on finding a function <span class="math inline">\(f(x)\)</span> that will input a variable <span class="math inline">\(x\)</span> to predict a value for <span class="math inline">\(y\)</span> and is the model in the lower right of Figure <a href="ml-overview.html#fig:model-compare">1.1</a>.</p>
</div>
<div id="what-machine-learning-is-not" class="section level2">
<h2><span class="header-section-number">1.2</span> What machine learning is not</h2>
<p>While machine learning has made significant breakthroughs in many areas (web search, image recognition, game AI, medical diagnosis, prediction, and classification to name a few), it is a technique that is not without limitations.For this course, we will cover a few of these limitations, but you can read a more in-depth critical analysis presented by <span class="citation">Marcus (<a href="#ref-marcus2018deep">2018</a>)</span>.</p>
<div id="machine-learning-models-require-a-lot-of-data" class="section level3 unnumbered">
<h3>Machine learning models require a lot of data</h3>
<p>For machine learning algorithms to learn well, they need lots of data. A review of the types of <a href="https://www.dezyre.com/article/top-10-industrial-applications-of-machine-learning/364">use cases</a> that these models have achieved a lot of success will give you an appreciation for the amount of data needed to train, validate, and use these models into a production environment.</p>
</div>
<div id="machine-learning-models-are-not-a-substitute-for-domain-expertise" class="section level3 unnumbered">
<h3>Machine learning models are not a substitute for domain expertise</h3>
<p>When appropriately used, machine learning models can help us to find hidden patterns in our data that are not possible on our own. While this is a great benefit, it does not alleviate the burden of understanding what these results mean, and whether they even matter when it comes to finding an adequate solution to a business problem.</p>
</div>
<div id="machine-learning-models-require-constant-maintenance" class="section level3 unnumbered">
<h3>Machine learning models require constant maintenance</h3>
<p>This statement should not come as a surprise since machine learning models are an extension of statistics in some ways. In general machine learning problems work best with applications that are similar to their training context. Even then, <a href="https://gizmodo.com/british-cops-want-to-use-ai-to-spot-porn-but-it-keeps-m-1821384511">mistakes</a> can happen, and the modeler must make adjustments.</p>
</div>
</div>
<div id="what-do-i-need-to-know-to-get-started-with-machine-learning" class="section level2">
<h2><span class="header-section-number">1.3</span> What do I need to know to get started with machine learning?</h2>
<p>Once you are familiar with the concepts in machine learning, you will realize that most of the ideas are similar to other statistical methods. The key here is learning the following thoughts.</p>
<div id="the-role-of-data-in-machine-learning" class="section level3 unnumbered">
<h3>The role of data in machine learning</h3>
<p>Machine learning algorithms primarily use tabular data. Nevertheless, machine learning literature has its origin in computer science, and some of the terms used to describe data are slightly different than traditional statistics. Primarily, the regressor variables in machine learning are called features. Features are used to make predictions on target or outcome measures.</p>
</div>
<div id="the-difference-between-parametric-and-nonparametric-machine-learning-algorithms" class="section level3 unnumbered">
<h3>The difference between parametric and nonparametric machine learning algorithms</h3>
<div id="parametric-models" class="section level4 unnumbered">
<h4>Parametric Models</h4>
<p>Parametric machine learning models are based on modeling assumptions about the mapping of the feature variables to the target variable. Some examples of parametric machine learning models are Linear Regression, Logistic Regression, and Linear Discriminant Analysis. In general parametric models are simpler, faster to compute, and require fewer data. A key drawback, however, is that parametric models are rigid and do not adjust well to variations in the data <span class="citation">(Brownlee <a href="#ref-brownlee2017mlmastery">2017</a><a href="#ref-brownlee2017mlmastery">b</a>)</span>.</p>
</div>
<div id="nonparametric-models" class="section level4 unnumbered">
<h4>Nonparametric Models</h4>
<p>Nonparametric machine learning models are not based on any modeling assumptions about the mapping of the feature variables to the target variable. Some examples of nonparametric models are <span class="math inline">\(k\)</span>-Nearest Neighbors, Naive Bayes, Support Vector Machines, Neural Networks, and Decision Trees. In general nonparametric models more complex, slower to compute, and require more data than parametric models. A principal drawback of nonparametric models is their inconsistent results <span class="citation">(Brownlee <a href="#ref-brownlee2017mlmastery">2017</a><a href="#ref-brownlee2017mlmastery">b</a>)</span>.</p>
</div>
</div>
<div id="the-difference-between-supervised-unsupervised-and-semi-supervised-learning" class="section level3 unnumbered">
<h3>The difference between supervised, unsupervised and semi-supervised learning</h3>
<p>The key takeaway here is that supervised learning models predict a value; unsupervised learning models describe associations and patterns in a dataset, and semi-supervised learning models are combinations of the two <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-friedman2001elements">2009</a>)</span>. Furthermore, supervised learning involves data that has labeled features and target variables. In contrast, unsupervised learning uses data that does not have any feature or target variable labels.</p>
</div>
<div id="the-bias-variance-tradeoff" class="section level3 unnumbered">
<h3>The bias-variance tradeoff</h3>
<p>The company EliteDataScience created an <a href="https://elitedatascience.com/bias-variance-tradeoff">infographic</a> that provides a vivid explanation of the importance of the bias-variance tradeoff. The key to this concept is to understand that bias is the degree to which the predictions or classifications are different from the actual value. Parametric models tend to have higher bias than nonparametric models. Conversely, variance refers to how sensitive the model is to noise in the data. For variance error, nonparametric models will tend to be more sensitive to different sets of training data than parametric models.</p>
<p>Another critical aspect is that bias and variance have an inverse relationship. In other words, models that usually have a high bias also have low variance. By contrast, models that have low bias will usually exhibit high variance. Hence, it is essential that you tune your modeling parameters and try as many different models as possible to evaluate model performance.</p>
</div>
<div id="overfitting-and-underfitting-and-what-to-do-about-it" class="section level3 unnumbered">
<h3>Overfitting and underfitting and what to do about it</h3>
<p>For underfitted models, the answer is simple; don’t use the model. Overfitting, however, is a different problem. In this case, the model fits the data too well to apply for any general setting. Thus, you will have to spend some time making adjustments to the model and determining how best to engineer the features to reduce the risk of overfitting.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-breiman2001statistical">
<p>Breiman, Leo. 2001. “Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author).” <em>Statistical Science</em> 16 (3). Institute of Mathematical Statistics: 199–231.</p>
</div>
<div id="ref-marcus2018deep">
<p>Marcus, Gary. 2018. “Deep Learning: A Critical Appraisal.” <em>arXiv Preprint arXiv:1801.00631</em>.</p>
</div>
<div id="ref-brownlee2017mlmastery">
<p>Brownlee, Jason. 2017b. <em>Master Machine Learning Algorithms</em>. <a href="https://machinelearningmastery.com/master-machine-learning-algorithms/" class="uri">https://machinelearningmastery.com/master-machine-learning-algorithms/</a>.</p>
</div>
<div id="ref-friedman2001elements">
<p>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning</em>. 2nd ed. Springer series in statistics New York. <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" class="uri">https://web.stanford.edu/~hastie/ElemStatLearn/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lin-algs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
